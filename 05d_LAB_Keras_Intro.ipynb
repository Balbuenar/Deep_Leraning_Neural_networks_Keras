{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "05d_LAB_Keras_Intro.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Balbuenar/Deep_Leraning_Neural_networks_Keras/blob/master/05d_LAB_Keras_Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "NDT-GJeVSS9k"
      },
      "source": [
        "# Machine Learning Foundation\n",
        "\n",
        "## Course 5, Part d: Keras Intro LAB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjCZOjumSS9s"
      },
      "source": [
        "## Using Keras to Build and Train Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2XBEBHISS9t"
      },
      "source": [
        "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
        "\n",
        "## UCI Pima Diabetes Dataset\n",
        "\n",
        "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
        "\n",
        "\n",
        "### Attributes: (all numeric-valued)\n",
        "   1. Number of times pregnant\n",
        "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "   3. Diastolic blood pressure (mm Hg)\n",
        "   4. Triceps skin fold thickness (mm)\n",
        "   5. 2-Hour serum insulin (mu U/ml)\n",
        "   6. Body mass index (weight in kg/(height in m)^2)\n",
        "   7. Diabetes pedigree function\n",
        "   8. Age (years)\n",
        "   9. Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKfSD6muSS9u"
      },
      "source": [
        "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3Q4UBZNSS9u"
      },
      "source": [
        "#Setup\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrkTAcEqSS9v"
      },
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "from tensorflow.keras.models  import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa26AsSUSS9w"
      },
      "source": [
        "## Load in the data set \n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv('/content/diabetes.csv', names=names, header=0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "TX5LQRO1SS9w",
        "outputId": "92d021be-bd9e-4b5f-f5e6-555bc06b0610"
      },
      "source": [
        "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768, 9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>1</td>\n",
              "      <td>108</td>\n",
              "      <td>88</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>27.1</td>\n",
              "      <td>0.400</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>1</td>\n",
              "      <td>109</td>\n",
              "      <td>60</td>\n",
              "      <td>8</td>\n",
              "      <td>182</td>\n",
              "      <td>25.4</td>\n",
              "      <td>0.947</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>0</td>\n",
              "      <td>161</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.9</td>\n",
              "      <td>0.254</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>70</td>\n",
              "      <td>26</td>\n",
              "      <td>50</td>\n",
              "      <td>30.8</td>\n",
              "      <td>0.597</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>0</td>\n",
              "      <td>127</td>\n",
              "      <td>80</td>\n",
              "      <td>37</td>\n",
              "      <td>210</td>\n",
              "      <td>36.3</td>\n",
              "      <td>0.804</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  ...  age  has_diabetes\n",
              "600               1                     108  ...   24             0\n",
              "382               1                     109  ...   21             0\n",
              "294               0                     161  ...   65             0\n",
              "136               0                     100  ...   21             0\n",
              "538               0                     127  ...   23             0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ii7qtmzSS9x"
      },
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EekyMvusSS9x"
      },
      "source": [
        "# Split the data to Train, and Test (75%, 25%)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S-0jWxmSS9x",
        "outputId": "6d5baf8f-2a17-48fb-d29c-05dca932698c"
      },
      "source": [
        "np.mean(y), np.mean(1-y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuE4aIliSS9y"
      },
      "source": [
        "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
        "## Exercise 1: Get a baseline performance using Random Forest\n",
        "To begin, and get a baseline for classifier performance:\n",
        "1. Train a Random Forest model with 200 trees on the training data.\n",
        "2. Calculate the accuracy and roc_auc_score of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ztfCDPwSS9y",
        "outputId": "651e67f3-60f2-4653-a4cb-8beab29fad8d"
      },
      "source": [
        "### BEGIN SOLUTION\n",
        "## Train the RF Model\n",
        "rf_model = RandomForestClassifier(n_estimators=200)\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR3wINa9SS9y",
        "outputId": "26dc26d1-5d4b-413d-f81f-b2c42aa1449e"
      },
      "source": [
        "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
        "y_pred_class_rf = rf_model.predict(X_test)\n",
        "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
        "\n",
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy is 0.771\n",
            "roc-auc is 0.835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "Hn3_OuSnSS9z",
        "outputId": "31154d9d-daf0-48b7-d3d4-f3c58675f549"
      },
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
        "### END SOLUTION"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_NwL1zESS9z"
      },
      "source": [
        "## Build a Single Hidden Layer Neural Network\n",
        "\n",
        "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhCLwMMTSS90"
      },
      "source": [
        "## First let's normalize the data\n",
        "## This aids the training of neural nets by providing numerical stability\n",
        "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
        "\n",
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arrm8O6PSS90"
      },
      "source": [
        "# Define the Model \n",
        "# Input size is 8-dimensional\n",
        "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
        "\n",
        "model_1 = Sequential()\n",
        "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
        "model_1.add(Dense(1,activation='sigmoid'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_VlPl2SSS90",
        "outputId": "86cb7e48-94cd-45f8-8cea-894fa0608dc3"
      },
      "source": [
        "#  This is a nice tool to view the model you have created and count the parameters\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 13        \n",
            "=================================================================\n",
            "Total params: 121\n",
            "Trainable params: 121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUPBXxe4SS90"
      },
      "source": [
        "### Comprehension question:\n",
        "Why do we have 121 parameters?  Does that make sense?\n",
        "\n",
        "Let's fit our model for 200 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23AWem9ESS91",
        "outputId": "f92ba968-78a3-4f14-931b-cc7bc6e162d5"
      },
      "source": [
        "# Fit(Train) the Model\n",
        "\n",
        "# Compile the model with Optimizer, Loss Function and Metrics\n",
        "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
        "\n",
        "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
        "# the fit function returns the run history. \n",
        "# It is very convenient, as it contains information about the model fit, iterations etc."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 15ms/step - loss: 0.7900 - accuracy: 0.3427 - val_loss: 0.7582 - val_accuracy: 0.3698\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7639 - accuracy: 0.3463 - val_loss: 0.7424 - val_accuracy: 0.3646\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7319 - accuracy: 0.3886 - val_loss: 0.7282 - val_accuracy: 0.3750\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7259 - accuracy: 0.3803 - val_loss: 0.7155 - val_accuracy: 0.3854\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7178 - accuracy: 0.4000 - val_loss: 0.7040 - val_accuracy: 0.4375\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7106 - accuracy: 0.3954 - val_loss: 0.6937 - val_accuracy: 0.4896\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.4964 - val_loss: 0.6844 - val_accuracy: 0.5000\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.5273 - val_loss: 0.6760 - val_accuracy: 0.5781\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6739 - accuracy: 0.6217 - val_loss: 0.6685 - val_accuracy: 0.5938\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6620 - accuracy: 0.6588 - val_loss: 0.6618 - val_accuracy: 0.6250\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.7058 - val_loss: 0.6557 - val_accuracy: 0.6615\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.7048 - val_loss: 0.6503 - val_accuracy: 0.6667\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6483 - accuracy: 0.7209 - val_loss: 0.6454 - val_accuracy: 0.6979\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6507 - accuracy: 0.6981 - val_loss: 0.6410 - val_accuracy: 0.7292\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.7262 - val_loss: 0.6370 - val_accuracy: 0.7552\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6343 - accuracy: 0.7348 - val_loss: 0.6334 - val_accuracy: 0.7292\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.7050 - val_loss: 0.6302 - val_accuracy: 0.7240\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6318 - accuracy: 0.7389 - val_loss: 0.6272 - val_accuracy: 0.7344\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.7348 - val_loss: 0.6245 - val_accuracy: 0.7083\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6193 - accuracy: 0.7346 - val_loss: 0.6221 - val_accuracy: 0.7031\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6242 - accuracy: 0.6924 - val_loss: 0.6199 - val_accuracy: 0.6875\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.7039 - val_loss: 0.6179 - val_accuracy: 0.6875\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6048 - accuracy: 0.7144 - val_loss: 0.6161 - val_accuracy: 0.6875\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.7087 - val_loss: 0.6144 - val_accuracy: 0.6927\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6089 - accuracy: 0.7089 - val_loss: 0.6129 - val_accuracy: 0.6875\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6034 - accuracy: 0.6939 - val_loss: 0.6115 - val_accuracy: 0.6927\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.6950 - val_loss: 0.6102 - val_accuracy: 0.6875\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6057 - accuracy: 0.6798 - val_loss: 0.6090 - val_accuracy: 0.6875\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6091 - accuracy: 0.6709 - val_loss: 0.6078 - val_accuracy: 0.6927\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6046 - accuracy: 0.6708 - val_loss: 0.6068 - val_accuracy: 0.6927\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.6540 - val_loss: 0.6059 - val_accuracy: 0.6927\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6012 - accuracy: 0.6542 - val_loss: 0.6050 - val_accuracy: 0.6927\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.6519 - val_loss: 0.6041 - val_accuracy: 0.6927\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.6565 - val_loss: 0.6033 - val_accuracy: 0.6927\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.6635 - val_loss: 0.6026 - val_accuracy: 0.6927\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.6314 - val_loss: 0.6019 - val_accuracy: 0.6927\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5967 - accuracy: 0.6714 - val_loss: 0.6012 - val_accuracy: 0.6927\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.6691 - val_loss: 0.6006 - val_accuracy: 0.6875\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.6650 - val_loss: 0.6000 - val_accuracy: 0.6875\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.6594 - val_loss: 0.5994 - val_accuracy: 0.6823\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.6885 - val_loss: 0.5988 - val_accuracy: 0.6771\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5851 - accuracy: 0.6792 - val_loss: 0.5983 - val_accuracy: 0.6771\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5930 - accuracy: 0.6630 - val_loss: 0.5978 - val_accuracy: 0.6771\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5950 - accuracy: 0.6565 - val_loss: 0.5973 - val_accuracy: 0.6719\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.6624 - val_loss: 0.5968 - val_accuracy: 0.6667\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.6745 - val_loss: 0.5963 - val_accuracy: 0.6667\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.6822 - val_loss: 0.5959 - val_accuracy: 0.6667\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6013 - accuracy: 0.6432 - val_loss: 0.5954 - val_accuracy: 0.6667\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.6514 - val_loss: 0.5950 - val_accuracy: 0.6615\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.6442 - val_loss: 0.5945 - val_accuracy: 0.6615\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5944 - accuracy: 0.6503 - val_loss: 0.5941 - val_accuracy: 0.6615\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.6513 - val_loss: 0.5937 - val_accuracy: 0.6615\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6011 - accuracy: 0.6500 - val_loss: 0.5933 - val_accuracy: 0.6615\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5814 - accuracy: 0.6642 - val_loss: 0.5929 - val_accuracy: 0.6615\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5729 - accuracy: 0.6862 - val_loss: 0.5925 - val_accuracy: 0.6615\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.6619 - val_loss: 0.5921 - val_accuracy: 0.6615\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.6738 - val_loss: 0.5917 - val_accuracy: 0.6615\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5756 - accuracy: 0.6819 - val_loss: 0.5913 - val_accuracy: 0.6615\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.6676 - val_loss: 0.5909 - val_accuracy: 0.6615\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5685 - accuracy: 0.6833 - val_loss: 0.5905 - val_accuracy: 0.6615\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.6641 - val_loss: 0.5901 - val_accuracy: 0.6615\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.6934 - val_loss: 0.5898 - val_accuracy: 0.6615\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.6237 - val_loss: 0.5894 - val_accuracy: 0.6615\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5717 - accuracy: 0.6844 - val_loss: 0.5890 - val_accuracy: 0.6615\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.6519 - val_loss: 0.5886 - val_accuracy: 0.6615\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.6992 - val_loss: 0.5883 - val_accuracy: 0.6615\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.6965 - val_loss: 0.5879 - val_accuracy: 0.6615\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.6951 - val_loss: 0.5875 - val_accuracy: 0.6615\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.6629 - val_loss: 0.5872 - val_accuracy: 0.6615\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.6853 - val_loss: 0.5868 - val_accuracy: 0.6615\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5890 - accuracy: 0.6453 - val_loss: 0.5864 - val_accuracy: 0.6615\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5785 - accuracy: 0.6624 - val_loss: 0.5861 - val_accuracy: 0.6615\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5817 - accuracy: 0.6612 - val_loss: 0.5857 - val_accuracy: 0.6615\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.6643 - val_loss: 0.5854 - val_accuracy: 0.6615\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.7044 - val_loss: 0.5850 - val_accuracy: 0.6615\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5830 - accuracy: 0.6584 - val_loss: 0.5846 - val_accuracy: 0.6615\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5811 - accuracy: 0.6642 - val_loss: 0.5843 - val_accuracy: 0.6615\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5687 - accuracy: 0.6746 - val_loss: 0.5839 - val_accuracy: 0.6615\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.6861 - val_loss: 0.5836 - val_accuracy: 0.6615\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.6832 - val_loss: 0.5832 - val_accuracy: 0.6615\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5757 - accuracy: 0.6576 - val_loss: 0.5828 - val_accuracy: 0.6615\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.6704 - val_loss: 0.5825 - val_accuracy: 0.6667\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.6684 - val_loss: 0.5821 - val_accuracy: 0.6719\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.6569 - val_loss: 0.5818 - val_accuracy: 0.6719\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.6813 - val_loss: 0.5814 - val_accuracy: 0.6719\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5753 - accuracy: 0.6626 - val_loss: 0.5811 - val_accuracy: 0.6719\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5728 - accuracy: 0.6643 - val_loss: 0.5807 - val_accuracy: 0.6719\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.6642 - val_loss: 0.5804 - val_accuracy: 0.6719\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.6990 - val_loss: 0.5800 - val_accuracy: 0.6719\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.6629 - val_loss: 0.5797 - val_accuracy: 0.6719\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.6396 - val_loss: 0.5793 - val_accuracy: 0.6719\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.6902 - val_loss: 0.5790 - val_accuracy: 0.6719\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5687 - accuracy: 0.6738 - val_loss: 0.5786 - val_accuracy: 0.6719\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5851 - accuracy: 0.6430 - val_loss: 0.5783 - val_accuracy: 0.6719\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.6731 - val_loss: 0.5779 - val_accuracy: 0.6823\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.6629 - val_loss: 0.5776 - val_accuracy: 0.6823\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.6671 - val_loss: 0.5772 - val_accuracy: 0.6875\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.6874 - val_loss: 0.5769 - val_accuracy: 0.6875\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.6703 - val_loss: 0.5765 - val_accuracy: 0.6875\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.6772 - val_loss: 0.5762 - val_accuracy: 0.6875\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5757 - accuracy: 0.6726 - val_loss: 0.5759 - val_accuracy: 0.6875\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5651 - accuracy: 0.6785 - val_loss: 0.5755 - val_accuracy: 0.6875\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.6263 - val_loss: 0.5752 - val_accuracy: 0.6875\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5762 - accuracy: 0.6696 - val_loss: 0.5748 - val_accuracy: 0.6875\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5520 - accuracy: 0.6984 - val_loss: 0.5745 - val_accuracy: 0.6875\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5600 - accuracy: 0.6827 - val_loss: 0.5741 - val_accuracy: 0.6875\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5645 - accuracy: 0.6714 - val_loss: 0.5738 - val_accuracy: 0.6927\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.6862 - val_loss: 0.5735 - val_accuracy: 0.6927\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.6944 - val_loss: 0.5731 - val_accuracy: 0.6927\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5615 - accuracy: 0.6829 - val_loss: 0.5728 - val_accuracy: 0.6927\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5619 - accuracy: 0.6820 - val_loss: 0.5725 - val_accuracy: 0.6927\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.6930 - val_loss: 0.5721 - val_accuracy: 0.6927\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.6937 - val_loss: 0.5718 - val_accuracy: 0.6927\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.6906 - val_loss: 0.5715 - val_accuracy: 0.6927\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.6560 - val_loss: 0.5711 - val_accuracy: 0.6927\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7249 - val_loss: 0.5708 - val_accuracy: 0.6927\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.6939 - val_loss: 0.5705 - val_accuracy: 0.6927\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5536 - accuracy: 0.6941 - val_loss: 0.5701 - val_accuracy: 0.6927\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.7052 - val_loss: 0.5698 - val_accuracy: 0.6927\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7075 - val_loss: 0.5695 - val_accuracy: 0.6927\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5704 - accuracy: 0.6696 - val_loss: 0.5691 - val_accuracy: 0.6927\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.6530 - val_loss: 0.5688 - val_accuracy: 0.6927\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.6923 - val_loss: 0.5685 - val_accuracy: 0.6927\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5575 - accuracy: 0.6768 - val_loss: 0.5682 - val_accuracy: 0.6927\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.6826 - val_loss: 0.5678 - val_accuracy: 0.6927\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5394 - accuracy: 0.7105 - val_loss: 0.5675 - val_accuracy: 0.6927\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7135 - val_loss: 0.5672 - val_accuracy: 0.6927\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5667 - accuracy: 0.6764 - val_loss: 0.5669 - val_accuracy: 0.6927\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7156 - val_loss: 0.5665 - val_accuracy: 0.6927\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.6849 - val_loss: 0.5662 - val_accuracy: 0.6927\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.6919 - val_loss: 0.5659 - val_accuracy: 0.6927\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7067 - val_loss: 0.5656 - val_accuracy: 0.6979\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5612 - accuracy: 0.6804 - val_loss: 0.5652 - val_accuracy: 0.6927\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.6744 - val_loss: 0.5649 - val_accuracy: 0.6927\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.6821 - val_loss: 0.5646 - val_accuracy: 0.6927\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.6768 - val_loss: 0.5643 - val_accuracy: 0.6927\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5480 - accuracy: 0.6990 - val_loss: 0.5640 - val_accuracy: 0.6927\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5662 - accuracy: 0.6735 - val_loss: 0.5637 - val_accuracy: 0.6927\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5615 - accuracy: 0.6873 - val_loss: 0.5633 - val_accuracy: 0.6927\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7068 - val_loss: 0.5630 - val_accuracy: 0.6927\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.6858 - val_loss: 0.5627 - val_accuracy: 0.6927\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5395 - accuracy: 0.7267 - val_loss: 0.5624 - val_accuracy: 0.6979\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.7080 - val_loss: 0.5621 - val_accuracy: 0.6979\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7214 - val_loss: 0.5618 - val_accuracy: 0.6979\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.6919 - val_loss: 0.5615 - val_accuracy: 0.7031\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.6966 - val_loss: 0.5612 - val_accuracy: 0.7031\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.6566 - val_loss: 0.5609 - val_accuracy: 0.7031\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5390 - accuracy: 0.7177 - val_loss: 0.5606 - val_accuracy: 0.7031\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.7083 - val_loss: 0.5602 - val_accuracy: 0.7083\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5523 - accuracy: 0.6949 - val_loss: 0.5599 - val_accuracy: 0.7083\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5525 - accuracy: 0.6965 - val_loss: 0.5596 - val_accuracy: 0.7083\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.6946 - val_loss: 0.5593 - val_accuracy: 0.7135\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7232 - val_loss: 0.5590 - val_accuracy: 0.7135\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7347 - val_loss: 0.5587 - val_accuracy: 0.7135\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.6848 - val_loss: 0.5584 - val_accuracy: 0.7188\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7190 - val_loss: 0.5581 - val_accuracy: 0.7188\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.6964 - val_loss: 0.5578 - val_accuracy: 0.7240\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.7036 - val_loss: 0.5575 - val_accuracy: 0.7240\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7196 - val_loss: 0.5572 - val_accuracy: 0.7240\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7223 - val_loss: 0.5569 - val_accuracy: 0.7240\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7170 - val_loss: 0.5566 - val_accuracy: 0.7240\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7213 - val_loss: 0.5563 - val_accuracy: 0.7240\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.6981 - val_loss: 0.5561 - val_accuracy: 0.7240\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7271 - val_loss: 0.5558 - val_accuracy: 0.7240\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7194 - val_loss: 0.5555 - val_accuracy: 0.7240\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.7060 - val_loss: 0.5552 - val_accuracy: 0.7240\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7205 - val_loss: 0.5549 - val_accuracy: 0.7240\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7378 - val_loss: 0.5546 - val_accuracy: 0.7292\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.7041 - val_loss: 0.5543 - val_accuracy: 0.7292\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7398 - val_loss: 0.5540 - val_accuracy: 0.7292\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5698 - accuracy: 0.6799 - val_loss: 0.5537 - val_accuracy: 0.7292\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7192 - val_loss: 0.5534 - val_accuracy: 0.7292\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5441 - accuracy: 0.7280 - val_loss: 0.5532 - val_accuracy: 0.7292\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7129 - val_loss: 0.5529 - val_accuracy: 0.7292\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.7052 - val_loss: 0.5526 - val_accuracy: 0.7292\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7397 - val_loss: 0.5523 - val_accuracy: 0.7292\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.7241 - val_loss: 0.5520 - val_accuracy: 0.7344\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.6946 - val_loss: 0.5517 - val_accuracy: 0.7344\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7353 - val_loss: 0.5515 - val_accuracy: 0.7396\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.7006 - val_loss: 0.5512 - val_accuracy: 0.7396\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5452 - accuracy: 0.7115 - val_loss: 0.5509 - val_accuracy: 0.7344\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7206 - val_loss: 0.5506 - val_accuracy: 0.7344\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7279 - val_loss: 0.5504 - val_accuracy: 0.7396\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.7059 - val_loss: 0.5501 - val_accuracy: 0.7396\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7469 - val_loss: 0.5498 - val_accuracy: 0.7396\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5317 - accuracy: 0.7166 - val_loss: 0.5495 - val_accuracy: 0.7396\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.7175 - val_loss: 0.5493 - val_accuracy: 0.7396\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7110 - val_loss: 0.5490 - val_accuracy: 0.7396\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7499 - val_loss: 0.5487 - val_accuracy: 0.7396\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5472 - accuracy: 0.7137 - val_loss: 0.5484 - val_accuracy: 0.7396\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7046 - val_loss: 0.5482 - val_accuracy: 0.7396\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7464 - val_loss: 0.5479 - val_accuracy: 0.7396\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7252 - val_loss: 0.5476 - val_accuracy: 0.7396\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7448 - val_loss: 0.5474 - val_accuracy: 0.7396\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7657 - val_loss: 0.5471 - val_accuracy: 0.7396\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7433 - val_loss: 0.5468 - val_accuracy: 0.7396\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7203 - val_loss: 0.5466 - val_accuracy: 0.7448\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7195 - val_loss: 0.5463 - val_accuracy: 0.7448\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7397 - val_loss: 0.5460 - val_accuracy: 0.7448\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7467 - val_loss: 0.5458 - val_accuracy: 0.7448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRyWwJHzSS91"
      },
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
        "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YSq6SUASS92",
        "outputId": "e11bdcc8-b7ed-4cd1-cb8d-7eec4615e858"
      },
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMtqivyZSS92",
        "outputId": "73405227-b285-406c-c66b-1d8e71f027ec"
      },
      "source": [
        "y_pred_prob_nn_1[:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4476124 ],\n",
              "       [0.5675205 ],\n",
              "       [0.31223696],\n",
              "       [0.31523296],\n",
              "       [0.25316826],\n",
              "       [0.47055644],\n",
              "       [0.1960927 ],\n",
              "       [0.39832455],\n",
              "       [0.59560084],\n",
              "       [0.31803113]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "bsX-9lMjSS93",
        "outputId": "724cf77d-4664-447e-de6c-44ea6c7db1c1"
      },
      "source": [
        "# Print model performance and plot the roc curve\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy is 0.745\n",
            "roc-auc is 0.814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1mLCF4eSS93"
      },
      "source": [
        "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yweGOHYsSS94"
      },
      "source": [
        "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up34fPBGSS95",
        "outputId": "9f24b6b2-e7c7-4264-c1ed-6099fe4b39c1"
      },
      "source": [
        "run_hist_1.history.keys()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkHfhNMGSS95"
      },
      "source": [
        "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ESralcczSS96",
        "outputId": "67c006d8-8e8d-4326-bc0e-145f24f0108c"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f55d9a29050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8dcnkwRcQFldgmxesFrCGsERkUBcEL3iXtCWILeiVKHYX9VqW+WBUpd6r177UxEVvVoql+otxYtolRqxNSqLiqKygwSXKiJgEUKS7/3jnAlDSMIkmS1n3s/Hg8fMnFnOJyfhfb7zPd/zPeacQ0REgisr1QWIiEhiKehFRAJOQS8iEnAKehGRgFPQi4gEXHaqC6ipffv2rmvXrqkuQ0SkWVm2bNlXzrkOtT2XdkHftWtXli5dmuoyRESaFTPbVNdz6roREQk4Bb2ISMAp6EVEAi7t+uhFJHn27t1LWVkZu3fvTnUpEqOWLVvSqVMncnJyYn6Pgl4kg5WVldGqVSu6du2KmaW6HDkI5xxbt26lrKyMbt26xfw+dd2IZLDdu3fTrl07hXwzYWa0a9euwd/AghX0paVw553erYjERCHfvDTm9xWcrpuXX4aRI6GqClq0gEWLIBxOdVUiIikXnBb9669DRYUX9OXlUFKS6opE5CC2bt1K37596du3L0cffTR5eXnVj8vLy+t979KlS5k8eXKD1te1a1e++uqrppTcLAWnRT9iBNx+O5hBbi4UFqa6IhE5iHbt2vHuu+8CMHXqVA4//HB+/vOfVz9fUVFBdnbtMVVQUEBBQUFS6mzugtOiP/VUOO44+P731W0jkkgJPhY2btw4rrnmGgYNGsSNN97I22+/TTgcpl+/fpx66qmsWrUKgJKSEs477zzA20mMHz+ewsJCunfvzgMPPBDz+jZu3Mjw4cPp3bs3RUVFfPLJJwD88Y9/pFevXvTp04fTTz8dgJUrVzJw4ED69u1L7969WbNmTZx/+sQIToseoEcP2L1bIS/SGFOmgN+6rtP27bBihddFmpUFvXvDEUfU/fq+feH++xtcSllZGW+88QahUIgdO3bw+uuvk52dzSuvvMItt9zCc889d8B7Pv74Y1599VV27tzJCSecwMSJE2Maaz5p0iSKi4spLi5m1qxZTJ48mXnz5jFt2jReeukl8vLy+OabbwCYMWMGP/3pT7niiisoLy+nsrKywT9bKgSnRQ+QlwdlZamuQiS4tm/3Qh682+3bE7KaSy+9lFAo5K9yO5deeim9evXi+uuvZ+XKlbW+59xzz6VFixa0b9+ejh078sUXX8S0rtLSUi6//HIAfvSjH/G3v/0NgMGDBzNu3DgeffTR6kAPh8P85je/4e6772bTpk0ccsghTf1RkyJYLfq8PPj0032tDRGJXSwt79JSKCryBjzk5sLs2Qn5Bn3YYYdV3//1r3/NsGHD+NOf/sTGjRsprOP4W4sWLarvh0IhKioqmlTDjBkzeOutt1iwYAEDBgxg2bJlXH755QwaNIgFCxYwcuRIHnnkEYYPH96k9SRDsNKwUydv5M2XX6a6EpFgCoe9Y2C33560Y2Hbt28nLy8PgCeffDLun3/qqacyZ84cAGbPns2QIUMAWLduHYMGDWLatGl06NCBzZs3s379erp3787kyZMZNWoUK1asiHs9iRC8Fj143TdHHZXaWkSCKhxO6nGwG2+8keLiYu644w7OPffcJn9e7969yfK/8V922WX87ne/48orr+S3v/0tHTp04IknngDghhtuYM2aNTjnKCoqok+fPtx99908/fTT5OTkcPTRR3PLLbc0uZ5kMOdcqmvYT0FBgWv0hUeWLIGBA+HPf4bzz49vYSIB9NFHH3HiiSemugxpoNp+b2a2zDlX63jT4HXdAGzZkto6RETSSLCCvmNHCIU08kZEJEqwgj4UgmOOUYteRCRKsIIevO4bBb2ISLVABf0bb8D0z/+N0qU5mqpYRMQXmKCfPx8GD3b8euOVFH3zLKWFNyvsRUQIUNC//7536whRTg4lewdrqmKRNDds2DBeeuml/Zbdf//9TJw4sc73FBYWEhmCPXLkyOp5aKJNnTqVe++9t951z5s3jw8//LD68a233sorr7zSkPJrFT3ZWroITNAPHw4GGFXkspfC7L9pqmKRNDdmzJjqs1Ij5syZw5gxY2J6/wsvvMCRRx7ZqHXXDPpp06ZxxhlnNOqz0l1ggj4chl75Rtf237KIIsLTz9MsliIJEM9Zii+55BIWLFhQfZGRjRs38umnnzJkyBAmTpxIQUEB3//+97nttttqfX/0hUSmT59Oz549Oe2006qnMgZ49NFHOfnkk+nTpw8XX3wxu3bt4o033mD+/PnccMMN9O3bl3Xr1jFu3DieffZZABYtWkS/fv3Iz89n/Pjx7Nmzp3p9t912G/379yc/P5+PP/445p/1mWeeIT8/n169enHTTTcBUFlZybhx4+jVqxf5+fncd999ADzwwAOcdNJJ9O7dm9GjRzdwqx4opikQzGwE8J9ACHjMOXdXjefvA4b5Dw8FOjrnjvSfqwT8jhU+cc4l7JTV/Hwo3X4oYd6EQ3+YqNWIBFIqZilu27YtAwcOZOHChYwaNYo5c+Zw2WWXYWZMnz6dtm3bUllZSVFREStWrKB37961fs6yZcuYM2cO7777LhUVFfTv358BAwYAcNFFF3HVVVcB8Ktf/YrHH3+cSZMmcf7553PeeedxySWX7PdZu3fvZty4cSxatIiePXsyduxYHn74YaZMmQJA+/btWb58OQ899BD33nsvjz32WP0bDfj000+56aabWLZsGW3atOGss85i3rx5HHfccWzZsoUPPvgAoLob6q677mLDhg20aNGi1q6phjpoi97MQsCDwDnAScAYMzsp+jXOueudc32dc32B3wH/E/X0d5HnEhnyAJ07w+ZPQ1TmHgKbNiVyVSIZKRGzFEd330R328ydO5f+/fvTr18/Vq5cuV83S02vv/46F154IYceeiitW7fm/KgpUD744AOGDBlCfn4+s2fPrnOa44hVq1bRrVs3evbsCUBxcTGLFy+ufv6iiy4CYMCAAWzcuDGmn3HJkiUUFhbSoUMHsrOzueKKK1i8eDHdu3dn/fr1TJo0iRdffJHWrVsD3nw8V1xxBb///e/rvMJWQ8TyCQOBtc659QBmNgcYBdS11ccAtX/PSrAuXaCiwvi8a3/y/KvEiEhsUjVL8ahRo7j++utZvnw5u3btYsCAAWzYsIF7772XJUuW0KZNG8aNG8fu3bsb9fnjxo1j3rx59OnThyeffJKSJg7SiEyHHI+pkNu0acN7773HSy+9xIwZM5g7dy6zZs1iwYIFLF68mOeff57p06fz/vvvNynwY+mjzwM2Rz0u85cdwMy6AN2Av0YtbmlmS83sTTO7oI73TfBfs/TLJkwx3Lmzd7upXX9Q0IvEXSJmKT788MMZNmwY48ePr27N79ixg8MOO4wjjjiCL774goULF9b7Gaeffjrz5s3ju+++Y+fOnTz//PPVz+3cuZNjjjmGvXv3Mnv27OrlrVq1YufOnQd81gknnMDGjRtZu3YtAE8//TRDhw5t0s84cOBAXnvtNb766isqKyt55plnGDp0KF999RVVVVVcfPHF3HHHHSxfvpyqqio2b97MsGHDuPvuu9m+fTvffvttk9Yf72mKRwPPOueir6/VxTm3xcy6A381s/edc+ui3+ScmwnMBG/2ysauvEsX7/aTw0/i1DUHXmpMRJouEbMUjxkzhgsvvLC6C6dPnz7069eP733vexx33HEMHjy43vf379+fH/zgB/Tp04eOHTty8sknVz93++23M2jQIDp06MCgQYOqw3306NFcddVVPPDAA9UHYQFatmzJE088waWXXkpFRQUnn3wy11xzTYN+nkWLFtEpMski3vVn77rrLoYNG4ZzjnPPPZdRo0bx3nvvceWVV1Ll94fdeeedVFZW8sMf/pDt27fjnGPy5MmNHlkUcdBpis0sDEx1zp3tP74ZwDl3Zy2vfQe41jn3Rh2f9STwv865Z2t7Hpo2TfHOndC6NdxV9DI3/fVs7/qxubmN+iyRTKBpipunRExTvAToYWbdzCwXr9U+v+aLzOx7QBugNGpZGzNr4d9vDwym7r79JmvVCtq0gU+qOoFzmvNGRIQYgt45VwFcB7wEfATMdc6tNLNpZhY9imY0MMft/xXhRGCpmb0HvArc5ZxLWNCD10+/aVcH78FvfqNpEEQk48XUR++cewF4ocayW2s8nlrL+94A8ptQX4O1agVL3z+MUk4hPGuWNywgSde2FGmOnHOYWarLkBg15qqAgTkzFrzG+5tvwhfbW1LEIkqrBnrjwDTnjUitWrZsydatWxsVHpJ8zjm2bt1Ky5YtG/S+QF0cvKQEKisBzJvYjGGEc9/TnDcidejUqRNlZWU0ZVizJFfLli33G9ETi0AFfWEh5OR4jfhsq6Lw6FXwnLptROqSk5NDt27dUl2GJFigum7CYYhMO/Gr3s8Tzl6ikBeRjBeooAe4wD/3Nqf9Ed5Fwv1Z8UREMlXggr5VK+jQAdZXdvbG0mtyMxHJcIELeoDu3WH9zo7egw0bUluMiEiKBTLou3WD9V+28h6sX5/aYkREUiyQQd+9O2zaEqIi5xC16EUk4wU26CsrjbK8QWrRi0jGC2zQA9zxzymUluzRfDciktECGfTbtnm3s748j6Kv5lBaeLPCXkQyViCD/qOPAByOkDcVwt7Bmu9GRDJWIIN++HDwJuOrIpe9FGb/TfPdiEjGCmTQh8Nw6qnGUa33sIgiwjcXaioEEclYgQx6gFNOge3lLRnE26kuRUQkpQIb9D17wu7dRlmnU2DNmlSXIyKSMoEN+h49vNs1HQcr6EUkowU26Hv29G5XH94fVq/2JjgTEclAgQ36Y4+FQw+F1XYC7NgBuoKOiGSowAa9mdd9s2ZXnrdA3TcikqECG/QA7drBm2vaUsopcN99OjtWRDJSYIO+tBQWL4at34QoYhGlz30KRUUKexHJOIEN+pISqKoCMMrJpYSh3mUFNRWCiGSYwAZ9YSHk5Hj3Q1RSSAnk5moqBBHJOIEN+nAYFi707o/t8QZhewtefFFTIYhIxgls0AMMG+ZdVvDbdt28cfTt26e6JBGRpAt00AOcdBJ89LV/oXBv/mIRkYwS+KA/8UT4eNMhVJIFH36Y6nJERJIu8EF/0kmwZ4+x4djT1KIXkYyUEUEPMK38Jkr/slPj6EUk4wQ+6Hfu9G5//9XZFG39b10/VkQyTkxBb2YjzGyVma01s1/U8vx9Zvau/2+1mX0T9Vyxma3x/xXHs/hYLFkCun6siGSy7IO9wMxCwIPAmUAZsMTM5jvnqo9sOueuj3r9JKCff78tcBtQADhgmf/ebXH9KepRWAhZWVBV5bzrx4Zeh8K7k7V6EZGUi6VFPxBY65xb75wrB+YAo+p5/RjgGf/+2cDLzrmv/XB/GRjRlIIbKhyGH/3IMHMsZATh4p46aUpEMkosQZ8HbI56XOYvO4CZdQG6AX9tyHvNbIKZLTWzpV8mYN74kSPBuSxaH9cGtiXty4SISFqI98HY0cCzzrnKhrzJOTfTOVfgnCvo0KFDnEuCPn282/c6ngkrVsT980VE0lksQb8FOC7qcSd/WW1Gs6/bpqHvTZh/+Rc45BBYkVsA69bBP/+Z7BJERFImlqBfAvQws25mlosX5vNrvsjMvge0AaLHLr4EnGVmbcysDXCWvyypQiHo2hX+vL4XpW4QrFyZ7BJERFLmoEHvnKsArsML6I+Auc65lWY2zczOj3rpaGCOc/uuwu2c+xq4HW9nsQSY5i9LqtJS7/rg6784zLsIyQ3/o7H0IpIxDjq8EsA59wLwQo1lt9Z4PLWO984CZjWyvrg44CIki7MIFxXBokUagSMigRf4M2PBG0ufm+vd9y5C8qquNiUiGSMjgj5yERIzx+U8Q5g3dbUpEckYGRH04F2EJD/f+Pz4wd6Cxx5Tt42IZISMCXqAggJYtq0bDqCyQUP9RUSarYwL+i+/zmZzix6wfHmqyxERSYqMCvoBA7zbW1r+B6VzNmmIpYhkhIwK+l27ABx/2D6Sos9/r7npRSQjZFTQRzLdkaW56UUkY2RU0BcWQnbIAf7c9FmLNcRSRAIvo4I+HIZf35oFGA9lTyZ8blsNsRSRwMuooAco9i9m+M8e/WDDhtQWIyKSBBkX9J07w7HHwhvZQ+CDD/ZdPVxEJKAyLujNoGdPWLjhe96UxVOmaOSNiARaxgV9aSn8/e+w7dtchvNXSmd9BEVFCnsRCayMC/qSkn2zH5STSwlDNZOliARaxgV9YSG0aAHgMKoopEQzWYpIoGVc0IfD3vVGTjjByGv9T2/K4oce0jBLEQmsjAt68DL9xz+GT3YcyWccDdu2pbokEZGEycigh309NdcfNpPSeV+ktBYRkUTK2KDfvdu7nfvPcylafCulj6xIbUEiIgmSsUH/+usAbt8EZ9f9UUMsRSSQMjboCwshJ6sKgBwqKKxYpCGWIhJIGRv04TD8YdpaAK7hYcJZb2mIpYgEUsYGPcAlvzyBTh338ELLiygNnQb9+6e6JBGRuMvooC8thc+/bsHq3V0o2ruQ0kv/Q/30IhI4GR30JSVQVQVg7CGXkud3at4bEQmcjA766OkQsnAU8qrmvRGRwMnooI9Mh3BSt10cyTZO4U3IydFBWREJlIwOevDC/sbbDuMrOnIdv6P0kn/XvDciEigZH/QARx0F4HiYn1A0+0pKZ76f6pJEROJGQQ+8845368ii3GVTcq3OkhWR4FDQs/9ZstlUUFips2RFJDhiCnozG2Fmq8xsrZn9oo7XXGZmH5rZSjP7Q9TySjN71/83P16Fx1M4DPPuWYVRyWXM1VmyIhIo5pyr/wVmIWA1cCZQBiwBxjjnPox6TQ9gLjDcObfNzDo65/7hP/etc+7wWAsqKChwS5cubfhPEgen9NrB6o8d/xu6gFN3vBgZeykikvbMbJlzrqC252Jp0Q8E1jrn1jvnyoE5wKgar7kKeNA5tw0gEvLNSWkpvLOmNdsqj2B4+UJKL7xb/fQiEgixBH0esDnqcZm/LFpPoKeZ/d3M3jSzEVHPtTSzpf7yC2pbgZlN8F+z9Msvv2zQDxAvB1w0fOF3OktWRAIhXgdjs4EeQCEwBnjUzI70n+vif524HLjfzI6v+Wbn3EznXIFzrqBDhw5xKqlhCgu9a4QbDocxiDd1lqyIBEIsQb8FOC7qcSd/WbQyYL5zbq9zbgNen34PAOfcFv92PVAC9GtizQkROUv2qvO/AIyHmUipnaqDsiLS7MUS9EuAHmbWzcxygdFAzdEz8/Ba85hZe7yunPVm1sbMWkQtHwx8SJoKh6H4pqMxczzLpRRVvkTpU2vUfSMizdpBg945VwFcB7wEfATMdc6tNLNpZna+/7KXgK1m9iHwKnCDc24rcCKw1Mze85ffFT1aJx299hqAAUa5y6HkkVXqqxeRZi07lhc5514AXqix7Nao+w74mf8v+jVvAPlNLzN5CguhZUv47juHAz5xnSjd059wSYnmwBGRZklnxtYQ6as/scsuqgjxKFdRVPUXStudl+rSREQaRUFfi3AYzhx1GGBUku0Nt3yndarLEhFpFAV9HUaPhqwsBzhyKadwVrH66UWkWVLQ1yEchgf/9UXA6McyqKjQmHoRaZYU9PXoM7ITWVTyBqd5/fRvh9SqF5FmR0Ffj5Kt+WBZgLGbFkyd14fSwpsV9iLSrCjo61FYCC1aGuBwZPEKZ1BU/oJ3EpWISDOhoK9HZKjloJO+BYwqQpSTQwlDU12aiEjMFPQHEQ7DfY+1IpRVBTgMo13rilSXJSISMwV9DMJhuGPCJwBUkMWUe47RBcRFpNlQ0MfIrd+IUQVksYdcSn67RAdlRaRZUNDHqPDidrRkD+CoIou1a51G4IhIs6Cgj1F4Qj6LHlnHqLavA8YTXKkROCLSLCjoGyA8IZ9Bl3Xxr0KVxW5a8NSHtV6LV0QkbSjoG6hwbBdyQt4IHEcWsxYfrwOzIpLWFPQNFA7D+AErMBxglJPLr2/eq7AXkbSloG+Esf+WQ0t2Y3jj6Rd93ZfTrz6BmTetS3FlIiIHUtA3QuTA7JltlgMOyKKCHK67t4sG4YhI2lHQN1J4Qj5T7zqEbCrA78bZW2VMnbJNYS8iaUVB3wThCfk8ePpcstlLpGX/8ttHUDSsUmEvImlDQd9EE+46nsW5Z1HEKwDesMs9xlP3fJbiykREPAr6pgqHCZfcye29nyPXP3PWYTw6ryMTJ+rEWRFJPQV9PITDhGcUM97+y58Px6gkxIwZjtNPh5kzU12giGQyBX28hMOMHbWdluzBqCRygLaiwvGTn6DWvYikjII+jsI3DmFR7kiuZiahqNE4lZWOGTNQ615EUkJBH09+f/3DZ83jIX5CDnv9rhxPRQVq3YtI0ino4y0chqlTmZD9JK8xlKt5JKp1D5WVqHUvIkmloE+EcBgefJBwzjIe5ifVrXvwJkMDte5FJHkU9IkyYQK89hqcdRYTeIzXGMo1dbTuCwsV+CKSOOacS3UN+ykoKHBLly5NdRnxU1rq9dNUeBOgzeTHXMeDVJCNwwCrfml2NvzsZ3DkkV74h8OpKVlEmh8zW+acq/UCGWrRJ5rfjUNODphVt+6v5hFasMc/WLuvO+eee+CXv1QfvojEj4I+GSLdOFdfDaEQYd7kYX7Cqww74GAtgHNe6E+cCKNGqVtHRJompqA3sxFmtsrM1prZL+p4zWVm9qGZrTSzP0QtLzazNf6/4ngV3uyEw/Dww/DQQ17rHqoDf99QzP0Dv6oK5s/3+vGHDIELLlDoi0jDHbSP3sxCwGrgTKAMWAKMcc59GPWaHsBcYLhzbpuZdXTO/cPM2gJLgQK8BFsGDHDObatrfYHro69NaSk89RTMmgXl5d4iTqGEQr7hSO7L+n9UuBDOWa1vz86Gc8+FY46BsWPVly8i9ffRxxL0YWCqc+5s//HNAM65O6Necw+w2jn3WI33jgEKnXNX+48fAUqcc8/Utb6MCPqISODPnOk13yOLOYWnrJjHs37M3srsej8iFIKRIyEvD/r1g61bdSBXJBPVF/T1p4gnD9gc9bgMGFTjNT39Ff0dCOHtGF6s4715tRQ4AZgA0Llz5xhKCohw2PvXrx9ce231yJwwbxJ2bzLW/Z6nuv6SzzmaBZv7sLfywJ62ykp4/vl9j8288NfoHRGJiCXoY/2cHkAh0AlYbGb5sb7ZOTcTmAleiz5ONTUfEyZAfr7Xun/0US+9gXDV3wlvHAlAaeg0njrxDj7v0IsFpe3Yu7f2j4ocyL3nHu9x9JDNdu3U4hfJRLEE/RbguKjHnfxl0cqAt5xze4ENZrYaL/i34IV/9HtLGltsoEW37q+7zkvrqG61cOXfCH9UCGuyKf3B/Ty1JsznLbvUG/qwf+jD/i3+HTu8ZernFwm2WPros/EOxhbhBfcS4HLn3Mqo14zAO0BbbGbtgXeAvuw7ANvff+lyvIOxX9e1vozqo69LpO/+8cepM8X9xC792R95ascFALRuDffdd8A+4qBycryDu0cfrX5+keaqSQdj/Q8YCdyP1/8+yzk33cymAUudc/PNzIB/B0YAlcB059wc/73jgVv8j5runHuivnUp6KNEAv/zz72OeL9LZz9ZWV5K5+XB2LGUEqakBL75Zv/QN4s9/NXqF2l+mhz0yaSgr8PMmbV26ewneghOVOhH+uZrhn9DZGfDeeep1S+SrhT0QVFaSq3N9dqEQnDOOdCp037N8chHtGsH77zjfVlYsKDuHqL6RA70qtUvknoK+iCKpR8/IhSCK66AwYO9dIcDwv+pp7zFje3nj6xm7Fg45ZRaVyMiCaSgD7LofvyGNM2jj8DWSON4tvpDITjrLOjSxevy0Q5AJDEU9JmisaEf3QFfRwLHq9UfvcrINA7q8xdpOgV9JooO/YULvdCPmmahTqEQnH02dO5cbwLX1upvyGpqU7PPXzsAkdgp6DNdU/tiYjzqGs8unwgN9RSJjYJeDtTYbh5o0PSZ0V0+kT76pu4AQiEoLoZBg9TnLxKhoJf6NSX0QyHvclg9esCAATH3tcS7zz8UgjPP9A769u+vHYBkHgW9xK6pCWzmtfhHjGjQ3Mk1u30au/qadNBXMoWCXhovXh3vjTy7KhEHfUMhmDQJdu/2HmsHIEGgoJf4qq+rJ9ZJdWoOsG9A0ibioC/oTF9p3hT0kji1HW2N5Wzd2oRC8NOfwq5d3uMGJG2iDvpedBEMGwYrVuz7bLX+JR0p6CW54jmnwtCh3oHe/v0blbDxPugboTH/km4U9JJa8Z5T4ZprvAO90UduG9nnD4ndAaj7R5JFQS/pJ95N7SZePSURB33B2y+dcQZ07aphn5JYCnpJf/E+whqHU2oT2fqPnkU6sl/SNX2lKRT00jzV1+pvyCWzIuI0qD6ROwBN+SCNpaCXYIhO2EgTOI2unpKoYZ+a6llioaCX4IvnSJ9hw+D44/eN9GlCn0qswz4b8wWlZvePdgCZTUEvmScN+/xrlhe9A2jqNX2jZWd7lw4+9ljtADKJgl4EmsXVUxLV/RMpd/x4b+45hX/wKOhFahNLqja0TyUBA+kTcdZvhIZ/BoeCXiRW8e5TqdnnH8ck1Q5AoinoRZoq3n0qCZw/ua4dQLxOACsqgm7dtANINwp6kUSIZ59/bfP4xzlFE9n/HwrB8OHeDiBy/RmdAJZcCnqRZEhUkjZxeoeDlZyo7p+I7GyYMgW+/XbferQDiD8FvUiqJGogfYKnz0zWDmDy5H2zUmsH0DQKepF0E895/COSMH9CIk8AiwiFYOJE7/PMdC5ArBT0Is1Boq6ekoTZ0xJ5Ali02s4F0DcBj4JepDlLxNVTkjR7WqLn/4+W6ReDUdCLBEmi0jOJcydoBxB/TQ56MxsB/CcQAh5zzt1V4/lxwG+BLf6i/++ce8x/rhJ431/+iXPu/PrWpaAXaaREnOkLCR3zX1NtO4B4nwsQEQrBtddCefn+64HmeSygSUFvZiFgNXAmUAgJjMUAAAfOSURBVAYsAcY45z6Mes04oMA5d10t7//WOXd4rMUq6EXiKFGd56GQN2Tmu+/2/+wEN5OT9U0gOxuKi2HgwOZzLKCpQR8GpjrnzvYf3wzgnLsz6jXjUNCLNB+JGvMfGTTftm2jrunbWMnuCqp5XkA6fBNoatBfAoxwzv3Yf/wjYFB0qPtBfyfwJV7r/3rn3Gb/uQrgXaACuMs5N6+WdUwAJgB07tx5wKZNmxr6M4pIUyVy8HwSu3+iJXMHAAf+mMncASQj6NsB3zrn9pjZ1cAPnHPD/efynHNbzKw78FegyDm3rq71qUUvkmYSMeoHvO6fSZNg927vcYp3AIk6FgB1zxEUzx854V03NV4fAr52zh1Ry3NPAv/rnHu2rvUp6EXSXCzN5KacMZUGcyYk85uAmTfLxTnneN8EGtv6b2rQZ+N1xxThjapZAlzunFsZ9ZpjnHOf+fcvBG5yzp1iZm2AXX5Lvz1QCoyKPpBbk4JepJlKxDV9o0XGSR55ZFL7/6Md7JtAPH7MFi3g1Vcb/iPFY3jlSOB+vOGVs5xz081sGrDUOTffzO4Ezsfrh/8amOic+9jMTgUeAaqALOB+59zj9a1LQS8SQInq/oEDJ31L4ZHRxhzmqPnlxwymT4ebb27YunXClIikl2T0jSRw1s+Gqm0HEH0/epqjlLXok0lBL5LBEt3/HwrBddfBnj3e4zQZHB+9I0hJH32yKehF5ACJ7v9P4QigeFHQi0hwJWr8f+SqX2eeCZ07p7z//2AU9CKSeRJ5ADgNL56roBcRaegB4MYcCwiFYOhQOP54KChI6kQ5CnoRkbrUNzi+qVf9qimBcyYr6EVEGiMZF8+N06mxCnoRkXhK5A6gkQPp6wv67KZVJCKSgcLh2oO4rjOjGnIsoLzc60qKY1++gl5EJF7q2gEAXHBBbMcCcnO9Pvs4UtCLiCRDfTuBsWObfmpsPRT0IiKpVt9OIA6yEvbJIiKSFhT0IiIBp6AXEQk4Bb2ISMAp6EVEAk5BLyIScGk3BYKZfQlsasJHtAe+ilM58aS6GiZd64L0rU11NUy61gWNq62Lc65DbU+kXdA3lZktrWu+h1RSXQ2TrnVB+tamuhomXeuC+NemrhsRkYBT0IuIBFwQg35mqguog+pqmHStC9K3NtXVMOlaF8S5tsD10YuIyP6C2KIXEZEoCnoRkYALTNCb2QgzW2Vma83sFyms4zgze9XMPjSzlWb2U3/5VDPbYmbv+v9Gpqi+jWb2vl/DUn9ZWzN72czW+LdtklzTCVHb5V0z22FmU1Kxzcxslpn9w8w+iFpW6/YxzwP+39wKM+uf5Lp+a2Yf++v+k5kd6S/vambfRW23GYmqq57a6vzdmdnN/jZbZWZnJ7mu/46qaaOZvesvT9o2qycjEvd35pxr9v+AELAO6A7kAu8BJ6WolmOA/v79VsBq4CRgKvDzNNhWG4H2NZbdA/zCv/8L4O4U/y4/B7qkYpsBpwP9gQ8Otn2AkcBCwIBTgLeSXNdZQLZ//+6ourpGvy5F26zW353/f+E9oAXQzf9/G0pWXTWe/3fg1mRvs3oyImF/Z0Fp0Q8E1jrn1jvnyoE5wKhUFOKc+8w5t9y/vxP4CMhLRS0NMAr4L//+fwEXpLCWImCdc64pZ0c3mnNuMfB1jcV1bZ9RwFPO8yZwpJkdk6y6nHN/cc5V+A/fBDolYt0HU8c2q8soYI5zbo9zbgOwFu//b1LrMjMDLgOeScS661NPRiTs7ywoQZ8HbI56XEYahKuZdQX6AW/5i67zv3rNSnb3SBQH/MXMlpnZBH/ZUc65z/z7nwNHpaY0AEaz/3++dNhmdW2fdPq7G4/X6ovoZmbvmNlrZjYkRTXV9rtLl202BPjCObcmalnSt1mNjEjY31lQgj7tmNnhwHPAFOfcDuBh4HigL/AZ3tfGVDjNOdcfOAe41sxOj37Sed8VUzLm1sxygfOBP/qL0mWbVUvl9qmLmf0SqABm+4s+Azo75/oBPwP+YGatk1xW2v3uahjD/g2KpG+zWjKiWrz/zoIS9FuA46Ied/KXpYSZ5eD9Amc75/4HwDn3hXOu0jlXBTxKgr6uHoxzbot/+w/gT34dX0S+Cvq3/0hFbXg7n+XOuS/8GtNim1H39kn5352ZjQPOA67wwwG/W2Srf38ZXj94z2TWVc/vLh22WTZwEfDfkWXJ3ma1ZQQJ/DsLStAvAXqYWTe/VTgamJ+KQvy+v8eBj5xz/xG1PLpP7ULgg5rvTUJth5lZq8h9vIN5H+Btq2L/ZcXAn5Ndm2+/VlY6bDNfXdtnPjDWHxVxCrA96qt3wpnZCOBG4Hzn3K6o5R3MLOTf7w70ANYnqy5/vXX97uYDo82shZl182t7O5m1AWcAHzvnyiILkrnN6soIEvl3loyjzMn4h3dkejXenviXKazjNLyvXCuAd/1/I4Gngff95fOBY1JQW3e8EQ/vASsj2wloBywC1gCvAG1TUNthwFbgiKhlSd9meDuaz4C9eH2h/1bX9sEbBfGg/zf3PlCQ5LrW4vXdRv7OZvivvdj//b4LLAf+NQXbrM7fHfBLf5utAs5JZl3+8ieBa2q8NmnbrJ6MSNjfmaZAEBEJuKB03YiISB0U9CIiAaegFxEJOAW9iEjAKehFRAJOQS8iEnAKehGRgPs/tlS9SqwwkVEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB_SyfhwSS96"
      },
      "source": [
        "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p7SlfDWSS96",
        "outputId": "35499bd2-e3cd-4b78-89b4-e71cf8537030"
      },
      "source": [
        "## Note that when we call \"fit\" again, it picks up where it left off\n",
        "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5332 - accuracy: 0.7344 - val_loss: 0.5455 - val_accuracy: 0.7448\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7361 - val_loss: 0.5453 - val_accuracy: 0.7448\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7361 - val_loss: 0.5450 - val_accuracy: 0.7448\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.7378 - val_loss: 0.5447 - val_accuracy: 0.7500\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7361 - val_loss: 0.5445 - val_accuracy: 0.7552\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7361 - val_loss: 0.5442 - val_accuracy: 0.7500\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7361 - val_loss: 0.5440 - val_accuracy: 0.7500\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7344 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7361 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7344 - val_loss: 0.5432 - val_accuracy: 0.7500\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7344 - val_loss: 0.5430 - val_accuracy: 0.7500\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7344 - val_loss: 0.5427 - val_accuracy: 0.7500\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7344 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7344 - val_loss: 0.5422 - val_accuracy: 0.7500\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7378 - val_loss: 0.5420 - val_accuracy: 0.7500\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7361 - val_loss: 0.5417 - val_accuracy: 0.7500\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7378 - val_loss: 0.5415 - val_accuracy: 0.7500\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7378 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7396 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7396 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7396 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7396 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7396 - val_loss: 0.5400 - val_accuracy: 0.7552\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7396 - val_loss: 0.5398 - val_accuracy: 0.7604\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7396 - val_loss: 0.5395 - val_accuracy: 0.7604\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7465 - val_loss: 0.5393 - val_accuracy: 0.7604\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5259 - accuracy: 0.7448 - val_loss: 0.5391 - val_accuracy: 0.7604\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7465 - val_loss: 0.5388 - val_accuracy: 0.7604\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7483 - val_loss: 0.5386 - val_accuracy: 0.7604\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7500 - val_loss: 0.5384 - val_accuracy: 0.7604\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.7517 - val_loss: 0.5381 - val_accuracy: 0.7604\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7517 - val_loss: 0.5379 - val_accuracy: 0.7604\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7535 - val_loss: 0.5377 - val_accuracy: 0.7604\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5241 - accuracy: 0.7552 - val_loss: 0.5374 - val_accuracy: 0.7604\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7552 - val_loss: 0.5372 - val_accuracy: 0.7604\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7535 - val_loss: 0.5370 - val_accuracy: 0.7604\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7535 - val_loss: 0.5367 - val_accuracy: 0.7604\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7535 - val_loss: 0.5365 - val_accuracy: 0.7604\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7552 - val_loss: 0.5363 - val_accuracy: 0.7604\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7552 - val_loss: 0.5360 - val_accuracy: 0.7604\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7535 - val_loss: 0.5358 - val_accuracy: 0.7604\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7535 - val_loss: 0.5356 - val_accuracy: 0.7604\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7535 - val_loss: 0.5354 - val_accuracy: 0.7604\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.7535 - val_loss: 0.5352 - val_accuracy: 0.7552\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7535 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.7517 - val_loss: 0.5347 - val_accuracy: 0.7500\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7517 - val_loss: 0.5345 - val_accuracy: 0.7500\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7517 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7517 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.7517 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7517 - val_loss: 0.5336 - val_accuracy: 0.7500\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.7500 - val_loss: 0.5334 - val_accuracy: 0.7500\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.7483 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7500 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7483 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7483 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.7465 - val_loss: 0.5323 - val_accuracy: 0.7448\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7448 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7448 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.7431 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5174 - accuracy: 0.7431 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7431 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7431 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7431 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7448 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5162 - accuracy: 0.7431 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5160 - accuracy: 0.7448 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7431 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7431 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7431 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7448 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7431 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5146 - accuracy: 0.7431 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7431 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.7431 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5139 - accuracy: 0.7431 - val_loss: 0.5285 - val_accuracy: 0.7552\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7431 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.7431 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7431 - val_loss: 0.5279 - val_accuracy: 0.7552\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.7431 - val_loss: 0.5277 - val_accuracy: 0.7552\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7431 - val_loss: 0.5275 - val_accuracy: 0.7552\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7431 - val_loss: 0.5273 - val_accuracy: 0.7552\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5124 - accuracy: 0.7431 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7431 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7396 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7413 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7413 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7396 - val_loss: 0.5262 - val_accuracy: 0.7604\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7431 - val_loss: 0.5260 - val_accuracy: 0.7604\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7431 - val_loss: 0.5258 - val_accuracy: 0.7604\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7431 - val_loss: 0.5256 - val_accuracy: 0.7604\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7431 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7431 - val_loss: 0.5253 - val_accuracy: 0.7604\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7431 - val_loss: 0.5251 - val_accuracy: 0.7604\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7448 - val_loss: 0.5249 - val_accuracy: 0.7656\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7448 - val_loss: 0.5247 - val_accuracy: 0.7656\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7448 - val_loss: 0.5245 - val_accuracy: 0.7656\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7448 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7448 - val_loss: 0.5242 - val_accuracy: 0.7708\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7465 - val_loss: 0.5240 - val_accuracy: 0.7708\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5085 - accuracy: 0.7448 - val_loss: 0.5238 - val_accuracy: 0.7708\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7465 - val_loss: 0.5237 - val_accuracy: 0.7708\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7483 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7500 - val_loss: 0.5233 - val_accuracy: 0.7656\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7500 - val_loss: 0.5231 - val_accuracy: 0.7656\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7517 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7517 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7517 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7500 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7517 - val_loss: 0.5223 - val_accuracy: 0.7656\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5218 - val_accuracy: 0.7656\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7500 - val_loss: 0.5215 - val_accuracy: 0.7656\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7517 - val_loss: 0.5213 - val_accuracy: 0.7656\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7517 - val_loss: 0.5211 - val_accuracy: 0.7656\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7552 - val_loss: 0.5210 - val_accuracy: 0.7656\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7535 - val_loss: 0.5208 - val_accuracy: 0.7656\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5048 - accuracy: 0.7552 - val_loss: 0.5206 - val_accuracy: 0.7656\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7569 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7569 - val_loss: 0.5203 - val_accuracy: 0.7656\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7569 - val_loss: 0.5202 - val_accuracy: 0.7656\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7569 - val_loss: 0.5200 - val_accuracy: 0.7656\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7569 - val_loss: 0.5199 - val_accuracy: 0.7604\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.7604\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5035 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.7604\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7569 - val_loss: 0.5194 - val_accuracy: 0.7604\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7587 - val_loss: 0.5192 - val_accuracy: 0.7604\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7587 - val_loss: 0.5191 - val_accuracy: 0.7604\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7587 - val_loss: 0.5189 - val_accuracy: 0.7604\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7622 - val_loss: 0.5188 - val_accuracy: 0.7604\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7604 - val_loss: 0.5186 - val_accuracy: 0.7604\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7622 - val_loss: 0.5185 - val_accuracy: 0.7604\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.7622 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7622 - val_loss: 0.5182 - val_accuracy: 0.7656\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7622 - val_loss: 0.5180 - val_accuracy: 0.7656\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7622 - val_loss: 0.5179 - val_accuracy: 0.7604\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7622 - val_loss: 0.5177 - val_accuracy: 0.7604\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7622 - val_loss: 0.5176 - val_accuracy: 0.7656\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7622 - val_loss: 0.5174 - val_accuracy: 0.7656\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7622 - val_loss: 0.5173 - val_accuracy: 0.7656\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7639 - val_loss: 0.5171 - val_accuracy: 0.7656\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7656 - val_loss: 0.5170 - val_accuracy: 0.7656\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7656 - val_loss: 0.5168 - val_accuracy: 0.7656\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7656 - val_loss: 0.5167 - val_accuracy: 0.7656\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.7674 - val_loss: 0.5166 - val_accuracy: 0.7656\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7656 - val_loss: 0.5164 - val_accuracy: 0.7656\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7639 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7639 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7639 - val_loss: 0.5160 - val_accuracy: 0.7656\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7656 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.7639 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7639 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7656 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4985 - accuracy: 0.7656 - val_loss: 0.5153 - val_accuracy: 0.7656\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.7639 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7622 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7622 - val_loss: 0.5149 - val_accuracy: 0.7760\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7622 - val_loss: 0.5148 - val_accuracy: 0.7760\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7639 - val_loss: 0.5146 - val_accuracy: 0.7760\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4975 - accuracy: 0.7639 - val_loss: 0.5145 - val_accuracy: 0.7760\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7639 - val_loss: 0.5144 - val_accuracy: 0.7760\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.7639 - val_loss: 0.5143 - val_accuracy: 0.7760\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7639 - val_loss: 0.5141 - val_accuracy: 0.7760\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7656 - val_loss: 0.5140 - val_accuracy: 0.7760\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7656 - val_loss: 0.5139 - val_accuracy: 0.7760\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.7656 - val_loss: 0.5137 - val_accuracy: 0.7760\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.7656 - val_loss: 0.5136 - val_accuracy: 0.7760\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7639 - val_loss: 0.5135 - val_accuracy: 0.7760\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7656 - val_loss: 0.5134 - val_accuracy: 0.7760\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7639 - val_loss: 0.5132 - val_accuracy: 0.7760\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4958 - accuracy: 0.7639 - val_loss: 0.5131 - val_accuracy: 0.7760\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7639 - val_loss: 0.5130 - val_accuracy: 0.7760\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7639 - val_loss: 0.5129 - val_accuracy: 0.7760\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7639 - val_loss: 0.5127 - val_accuracy: 0.7760\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7639 - val_loss: 0.5126 - val_accuracy: 0.7760\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4950 - accuracy: 0.7639 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7639 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7639 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7639 - val_loss: 0.5121 - val_accuracy: 0.7708\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7622 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7604 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7604 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7604 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7604 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7604 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7604 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4934 - accuracy: 0.7604 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7622 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7604 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4930 - accuracy: 0.7622 - val_loss: 0.5108 - val_accuracy: 0.7656\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7622 - val_loss: 0.5107 - val_accuracy: 0.7656\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7622 - val_loss: 0.5106 - val_accuracy: 0.7656\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7622 - val_loss: 0.5105 - val_accuracy: 0.7656\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7622 - val_loss: 0.5104 - val_accuracy: 0.7656\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.7622 - val_loss: 0.5103 - val_accuracy: 0.7656\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7604 - val_loss: 0.5102 - val_accuracy: 0.7656\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7622 - val_loss: 0.5101 - val_accuracy: 0.7656\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4919 - accuracy: 0.7604 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4918 - accuracy: 0.7604 - val_loss: 0.5098 - val_accuracy: 0.7604\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4917 - accuracy: 0.7604 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7622 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7604 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7604 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7604 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4910 - accuracy: 0.7604 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7604 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4907 - accuracy: 0.7604 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7604 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7604 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7604 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4902 - accuracy: 0.7604 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.7604 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7604 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7604 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7604 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7604 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7604 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4893 - accuracy: 0.7604 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7604 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7604 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4889 - accuracy: 0.7604 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4888 - accuracy: 0.7604 - val_loss: 0.5075 - val_accuracy: 0.7656\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.7622 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4886 - accuracy: 0.7622 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4885 - accuracy: 0.7622 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4883 - accuracy: 0.7622 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.7622 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7604 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7622 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.7622 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4877 - accuracy: 0.7622 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4876 - accuracy: 0.7622 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4875 - accuracy: 0.7622 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7622 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7622 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7622 - val_loss: 0.5062 - val_accuracy: 0.7708\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7622 - val_loss: 0.5061 - val_accuracy: 0.7708\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4869 - accuracy: 0.7622 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.7622 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.7622 - val_loss: 0.5058 - val_accuracy: 0.7708\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.7622 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4865 - accuracy: 0.7622 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.7622 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4862 - accuracy: 0.7622 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4861 - accuracy: 0.7622 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.7622 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7622 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7622 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7622 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7622 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7622 - val_loss: 0.5049 - val_accuracy: 0.7552\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7622 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7622 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7622 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7622 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7622 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7622 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7622 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7622 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7622 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7622 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7622 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7622 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7622 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7622 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7622 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7622 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7622 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4836 - accuracy: 0.7622 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.7622 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7622 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4833 - accuracy: 0.7622 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4832 - accuracy: 0.7622 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4831 - accuracy: 0.7622 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4830 - accuracy: 0.7622 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7622 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.7622 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7604 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7604 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4825 - accuracy: 0.7604 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4824 - accuracy: 0.7604 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4823 - accuracy: 0.7604 - val_loss: 0.5025 - val_accuracy: 0.7552\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4822 - accuracy: 0.7604 - val_loss: 0.5024 - val_accuracy: 0.7552\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7604 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.7604 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.7604 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4819 - accuracy: 0.7604 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4818 - accuracy: 0.7622 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7604 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7622 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4815 - accuracy: 0.7622 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7622 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7622 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4812 - accuracy: 0.7639 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4811 - accuracy: 0.7639 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7622 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7622 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4809 - accuracy: 0.7639 - val_loss: 0.5014 - val_accuracy: 0.7552\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7639 - val_loss: 0.5013 - val_accuracy: 0.7552\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4807 - accuracy: 0.7639 - val_loss: 0.5013 - val_accuracy: 0.7552\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4806 - accuracy: 0.7639 - val_loss: 0.5012 - val_accuracy: 0.7552\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7639 - val_loss: 0.5011 - val_accuracy: 0.7552\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7639 - val_loss: 0.5011 - val_accuracy: 0.7552\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4803 - accuracy: 0.7639 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4802 - accuracy: 0.7639 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4802 - accuracy: 0.7639 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7639 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4800 - accuracy: 0.7639 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7639 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4798 - accuracy: 0.7639 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7639 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.7639 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.7639 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7639 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7639 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.7639 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7639 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4792 - accuracy: 0.7639 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7639 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.7639 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4789 - accuracy: 0.7639 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7639 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7656 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7639 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7656 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4785 - accuracy: 0.7656 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7656 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4783 - accuracy: 0.7656 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4783 - accuracy: 0.7656 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7656 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7656 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7656 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7674 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7656 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.7656 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7674 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7674 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7674 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7674 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.7674 - val_loss: 0.4989 - val_accuracy: 0.7500\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.7674 - val_loss: 0.4989 - val_accuracy: 0.7500\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7674 - val_loss: 0.4988 - val_accuracy: 0.7500\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4772 - accuracy: 0.7674 - val_loss: 0.4988 - val_accuracy: 0.7500\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7674 - val_loss: 0.4987 - val_accuracy: 0.7500\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7674 - val_loss: 0.4987 - val_accuracy: 0.7500\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7674 - val_loss: 0.4986 - val_accuracy: 0.7500\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7674 - val_loss: 0.4986 - val_accuracy: 0.7500\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7674 - val_loss: 0.4985 - val_accuracy: 0.7500\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7691 - val_loss: 0.4985 - val_accuracy: 0.7500\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4767 - accuracy: 0.7691 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.7691 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.7691 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.7691 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4764 - accuracy: 0.7691 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4763 - accuracy: 0.7691 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7691 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7674 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.7674 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7674 - val_loss: 0.4980 - val_accuracy: 0.7448\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7674 - val_loss: 0.4979 - val_accuracy: 0.7448\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4759 - accuracy: 0.7674 - val_loss: 0.4979 - val_accuracy: 0.7448\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7674 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.7674 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7674 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7674 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4756 - accuracy: 0.7674 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7674 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4754 - accuracy: 0.7674 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4754 - accuracy: 0.7674 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.7656 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7674 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4752 - accuracy: 0.7656 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4751 - accuracy: 0.7656 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7656 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7656 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7656 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7656 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7656 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4747 - accuracy: 0.7656 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7656 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4746 - accuracy: 0.7674 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.7656 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.7674 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7674 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7674 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.7674 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.7674 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.7674 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7674 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7674 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7674 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4739 - accuracy: 0.7674 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7708 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4738 - accuracy: 0.7708 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7691 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7691 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7708 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.7708 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7708 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7708 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7708 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7708 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7708 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.7726 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.7708 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7708 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4731 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7726 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7726 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.7726 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.7726 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.7726 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7726 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7726 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7726 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7726 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7708 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.7708 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.7726 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7726 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.7726 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.7726 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7726 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7743 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7726 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7726 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7726 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7726 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7726 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7726 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7726 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7726 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7726 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7726 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7743 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7743 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7743 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7743 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7743 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7760 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7778 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7760 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4710 - accuracy: 0.7778 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4710 - accuracy: 0.7778 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7760 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7795 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4708 - accuracy: 0.7795 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4708 - accuracy: 0.7795 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7795 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7778 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7795 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7795 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7795 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7795 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7795 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7795 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7795 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7795 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.7795 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7795 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.7795 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7795 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7795 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7795 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7795 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7795 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7795 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7795 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7795 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7795 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7812 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7795 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7812 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7812 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7812 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7812 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.7812 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.7812 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4693 - accuracy: 0.7812 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7812 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7812 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.7812 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.7812 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4689 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4685 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4685 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7812 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7812 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7812 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.7795 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.7795 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.7795 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.7795 - val_loss: 0.4922 - val_accuracy: 0.7396\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.7795 - val_loss: 0.4922 - val_accuracy: 0.7396\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7795 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.7795 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7795 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.7795 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7795 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7795 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7795 - val_loss: 0.4920 - val_accuracy: 0.7396\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7795 - val_loss: 0.4920 - val_accuracy: 0.7396\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7795 - val_loss: 0.4920 - val_accuracy: 0.7396\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7795 - val_loss: 0.4920 - val_accuracy: 0.7396\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.7795 - val_loss: 0.4920 - val_accuracy: 0.7396\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.7795 - val_loss: 0.4920 - val_accuracy: 0.7396\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.7795 - val_loss: 0.4919 - val_accuracy: 0.7396\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7396\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7795 - val_loss: 0.4919 - val_accuracy: 0.7396\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7795 - val_loss: 0.4919 - val_accuracy: 0.7396\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7396\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.7795 - val_loss: 0.4919 - val_accuracy: 0.7396\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.7795 - val_loss: 0.4918 - val_accuracy: 0.7396\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7795 - val_loss: 0.4918 - val_accuracy: 0.7396\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7396\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7396\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7760 - val_loss: 0.4918 - val_accuracy: 0.7396\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7396\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7396\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7396\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7760 - val_loss: 0.4917 - val_accuracy: 0.7396\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7396\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.7760 - val_loss: 0.4917 - val_accuracy: 0.7396\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.7760 - val_loss: 0.4917 - val_accuracy: 0.7396\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7396\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7760 - val_loss: 0.4916 - val_accuracy: 0.7396\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7778 - val_loss: 0.4916 - val_accuracy: 0.7396\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7760 - val_loss: 0.4916 - val_accuracy: 0.7396\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7760 - val_loss: 0.4916 - val_accuracy: 0.7396\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7778 - val_loss: 0.4916 - val_accuracy: 0.7396\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7760 - val_loss: 0.4916 - val_accuracy: 0.7396\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7760 - val_loss: 0.4916 - val_accuracy: 0.7396\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7760 - val_loss: 0.4915 - val_accuracy: 0.7396\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7760 - val_loss: 0.4915 - val_accuracy: 0.7396\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7778 - val_loss: 0.4915 - val_accuracy: 0.7396\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7760 - val_loss: 0.4915 - val_accuracy: 0.7396\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7760 - val_loss: 0.4915 - val_accuracy: 0.7396\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7760 - val_loss: 0.4915 - val_accuracy: 0.7396\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7778 - val_loss: 0.4915 - val_accuracy: 0.7396\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7778 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7778 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7778 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7778 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7778 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7778 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7778 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7778 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7778 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7778 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7778 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7778 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7778 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7778 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4646 - accuracy: 0.7778 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7778 - val_loss: 0.4911 - val_accuracy: 0.7396\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7778 - val_loss: 0.4911 - val_accuracy: 0.7396\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7778 - val_loss: 0.4911 - val_accuracy: 0.7396\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.7778 - val_loss: 0.4911 - val_accuracy: 0.7396\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.7778 - val_loss: 0.4911 - val_accuracy: 0.7396\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.7778 - val_loss: 0.4911 - val_accuracy: 0.7396\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.7778 - val_loss: 0.4911 - val_accuracy: 0.7396\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.7778 - val_loss: 0.4911 - val_accuracy: 0.7396\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.7795 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.7795 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.7795 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.7795 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.7795 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.7795 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.7778 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7812 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4624 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4624 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4624 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "tBkvh7ocSS97",
        "outputId": "179afd4e-d66f-4c28-f2ba-c0449e2b15e0"
      },
      "source": [
        "n = len(run_hist_1.history[\"loss\"])\n",
        "m = len(run_hist_1b.history['loss'])\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
        "\n",
        "ax.legend()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f55e0faa850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QMyyPOySS97"
      },
      "source": [
        "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCWK4xbVSS97"
      },
      "source": [
        "## Exercise 2\n",
        "For this exercise, do the following in the cells below:\n",
        "- Build a model with two hidden layers, each with 6 nodes\n",
        "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "- Use a learning rate of .003 and train for 1500 epochs\n",
        "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "- Plot the roc curve for the predictions\n",
        "\n",
        "Experiment with different learning rates, numbers of epochs, and network structures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGs-SihbSS97",
        "outputId": "a16c305c-7d9a-4dc5-db6c-8f6678b5e69f"
      },
      "source": [
        "### BEGIN SOLUTION\n",
        "model_2 = Sequential()\n",
        "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
        "model_2.add(Dense(6,  activation=\"relu\"))\n",
        "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 1s 13ms/step - loss: 0.7207 - accuracy: 0.5343 - val_loss: 0.7675 - val_accuracy: 0.4635\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7308 - accuracy: 0.5248 - val_loss: 0.7630 - val_accuracy: 0.4635\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7084 - accuracy: 0.5522 - val_loss: 0.7586 - val_accuracy: 0.4688\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7013 - accuracy: 0.5439 - val_loss: 0.7545 - val_accuracy: 0.4688\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7169 - accuracy: 0.5228 - val_loss: 0.7506 - val_accuracy: 0.4740\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7094 - accuracy: 0.5412 - val_loss: 0.7468 - val_accuracy: 0.4792\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6977 - accuracy: 0.5492 - val_loss: 0.7432 - val_accuracy: 0.4948\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6961 - accuracy: 0.5829 - val_loss: 0.7398 - val_accuracy: 0.4948\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.5924 - val_loss: 0.7364 - val_accuracy: 0.4948\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5568 - val_loss: 0.7332 - val_accuracy: 0.5000\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6967 - accuracy: 0.5643 - val_loss: 0.7302 - val_accuracy: 0.5104\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6888 - accuracy: 0.5794 - val_loss: 0.7273 - val_accuracy: 0.5156\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6957 - accuracy: 0.5809 - val_loss: 0.7244 - val_accuracy: 0.5260\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5788 - val_loss: 0.7217 - val_accuracy: 0.5260\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.5866 - val_loss: 0.7190 - val_accuracy: 0.5208\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.6176 - val_loss: 0.7165 - val_accuracy: 0.5260\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.6208 - val_loss: 0.7140 - val_accuracy: 0.5312\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6838 - accuracy: 0.6083 - val_loss: 0.7116 - val_accuracy: 0.5573\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.5814 - val_loss: 0.7093 - val_accuracy: 0.5625\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6591 - accuracy: 0.6422 - val_loss: 0.7071 - val_accuracy: 0.5677\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6803 - accuracy: 0.5952 - val_loss: 0.7050 - val_accuracy: 0.5729\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.6178 - val_loss: 0.7029 - val_accuracy: 0.5729\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6701 - accuracy: 0.6161 - val_loss: 0.7009 - val_accuracy: 0.5781\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.6095 - val_loss: 0.6989 - val_accuracy: 0.5781\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6600 - accuracy: 0.6237 - val_loss: 0.6969 - val_accuracy: 0.5781\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6485 - accuracy: 0.6719 - val_loss: 0.6950 - val_accuracy: 0.5938\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.6336 - val_loss: 0.6931 - val_accuracy: 0.6146\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6595 - accuracy: 0.6454 - val_loss: 0.6913 - val_accuracy: 0.6146\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6563 - accuracy: 0.6507 - val_loss: 0.6896 - val_accuracy: 0.6146\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6701 - accuracy: 0.6293 - val_loss: 0.6878 - val_accuracy: 0.6146\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6543 - accuracy: 0.6334 - val_loss: 0.6861 - val_accuracy: 0.6198\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6706 - accuracy: 0.5963 - val_loss: 0.6845 - val_accuracy: 0.6302\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6478 - accuracy: 0.6641 - val_loss: 0.6828 - val_accuracy: 0.6302\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6546 - accuracy: 0.6492 - val_loss: 0.6812 - val_accuracy: 0.6302\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6557 - accuracy: 0.6575 - val_loss: 0.6797 - val_accuracy: 0.6354\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6480 - accuracy: 0.6578 - val_loss: 0.6782 - val_accuracy: 0.6354\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.6886 - val_loss: 0.6767 - val_accuracy: 0.6354\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6410 - accuracy: 0.6736 - val_loss: 0.6752 - val_accuracy: 0.6458\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.6946 - val_loss: 0.6738 - val_accuracy: 0.6458\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6423 - accuracy: 0.6611 - val_loss: 0.6724 - val_accuracy: 0.6458\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.7074 - val_loss: 0.6710 - val_accuracy: 0.6458\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6351 - accuracy: 0.6903 - val_loss: 0.6697 - val_accuracy: 0.6562\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.6792 - val_loss: 0.6683 - val_accuracy: 0.6510\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6192 - accuracy: 0.7114 - val_loss: 0.6670 - val_accuracy: 0.6510\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.6840 - val_loss: 0.6658 - val_accuracy: 0.6510\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.7006 - val_loss: 0.6645 - val_accuracy: 0.6510\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.6858 - val_loss: 0.6632 - val_accuracy: 0.6510\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6875 - val_loss: 0.6619 - val_accuracy: 0.6510\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.6970 - val_loss: 0.6607 - val_accuracy: 0.6562\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.6531 - val_loss: 0.6594 - val_accuracy: 0.6510\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.6862 - val_loss: 0.6582 - val_accuracy: 0.6562\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6197 - accuracy: 0.6976 - val_loss: 0.6570 - val_accuracy: 0.6562\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.6776 - val_loss: 0.6558 - val_accuracy: 0.6562\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6248 - accuracy: 0.6864 - val_loss: 0.6546 - val_accuracy: 0.6562\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.6883 - val_loss: 0.6535 - val_accuracy: 0.6562\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.6812 - val_loss: 0.6523 - val_accuracy: 0.6562\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6115 - accuracy: 0.7062 - val_loss: 0.6511 - val_accuracy: 0.6562\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6195 - accuracy: 0.6892 - val_loss: 0.6499 - val_accuracy: 0.6562\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.7015 - val_loss: 0.6488 - val_accuracy: 0.6562\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6135 - accuracy: 0.7035 - val_loss: 0.6476 - val_accuracy: 0.6562\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.7470 - val_loss: 0.6465 - val_accuracy: 0.6562\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6178 - accuracy: 0.6966 - val_loss: 0.6453 - val_accuracy: 0.6615\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6051 - accuracy: 0.7064 - val_loss: 0.6442 - val_accuracy: 0.6562\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6191 - accuracy: 0.6963 - val_loss: 0.6431 - val_accuracy: 0.6562\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.6972 - val_loss: 0.6420 - val_accuracy: 0.6562\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6164 - accuracy: 0.6769 - val_loss: 0.6408 - val_accuracy: 0.6562\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.6954 - val_loss: 0.6396 - val_accuracy: 0.6562\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6036 - accuracy: 0.6957 - val_loss: 0.6385 - val_accuracy: 0.6615\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5982 - accuracy: 0.7192 - val_loss: 0.6373 - val_accuracy: 0.6615\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6101 - accuracy: 0.7025 - val_loss: 0.6362 - val_accuracy: 0.6719\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6036 - accuracy: 0.7104 - val_loss: 0.6350 - val_accuracy: 0.6719\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6005 - accuracy: 0.7030 - val_loss: 0.6338 - val_accuracy: 0.6771\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.7240 - val_loss: 0.6327 - val_accuracy: 0.6823\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.7365 - val_loss: 0.6316 - val_accuracy: 0.6823\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6224 - accuracy: 0.6697 - val_loss: 0.6305 - val_accuracy: 0.6875\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.7239 - val_loss: 0.6294 - val_accuracy: 0.6875\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6017 - accuracy: 0.7172 - val_loss: 0.6283 - val_accuracy: 0.6875\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5992 - accuracy: 0.6955 - val_loss: 0.6271 - val_accuracy: 0.6875\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.6985 - val_loss: 0.6260 - val_accuracy: 0.6875\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.7133 - val_loss: 0.6249 - val_accuracy: 0.6875\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.6983 - val_loss: 0.6238 - val_accuracy: 0.6875\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.6774 - val_loss: 0.6227 - val_accuracy: 0.6875\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5926 - accuracy: 0.7075 - val_loss: 0.6216 - val_accuracy: 0.6875\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.7158 - val_loss: 0.6206 - val_accuracy: 0.6875\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5968 - accuracy: 0.7087 - val_loss: 0.6195 - val_accuracy: 0.6875\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.7040 - val_loss: 0.6184 - val_accuracy: 0.6875\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.7096 - val_loss: 0.6173 - val_accuracy: 0.6875\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.6890 - val_loss: 0.6162 - val_accuracy: 0.6875\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.7174 - val_loss: 0.6151 - val_accuracy: 0.6875\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5977 - accuracy: 0.6806 - val_loss: 0.6141 - val_accuracy: 0.6875\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.7289 - val_loss: 0.6130 - val_accuracy: 0.6875\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.6982 - val_loss: 0.6119 - val_accuracy: 0.6875\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.6981 - val_loss: 0.6108 - val_accuracy: 0.6875\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5802 - accuracy: 0.7021 - val_loss: 0.6098 - val_accuracy: 0.6875\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.7394 - val_loss: 0.6088 - val_accuracy: 0.6875\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.6872 - val_loss: 0.6077 - val_accuracy: 0.6875\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.7224 - val_loss: 0.6068 - val_accuracy: 0.6875\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.7277 - val_loss: 0.6058 - val_accuracy: 0.6875\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.6926 - val_loss: 0.6048 - val_accuracy: 0.6875\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5645 - accuracy: 0.7155 - val_loss: 0.6038 - val_accuracy: 0.6875\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.6921 - val_loss: 0.6029 - val_accuracy: 0.6875\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5652 - accuracy: 0.7155 - val_loss: 0.6019 - val_accuracy: 0.6927\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.7288 - val_loss: 0.6009 - val_accuracy: 0.6927\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5691 - accuracy: 0.7099 - val_loss: 0.6000 - val_accuracy: 0.6927\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5693 - accuracy: 0.7121 - val_loss: 0.5990 - val_accuracy: 0.6927\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.6924 - val_loss: 0.5981 - val_accuracy: 0.6927\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5631 - accuracy: 0.7146 - val_loss: 0.5971 - val_accuracy: 0.6927\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.7016 - val_loss: 0.5962 - val_accuracy: 0.6927\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.7146 - val_loss: 0.5953 - val_accuracy: 0.6927\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5464 - accuracy: 0.7332 - val_loss: 0.5943 - val_accuracy: 0.6927\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.7073 - val_loss: 0.5934 - val_accuracy: 0.6875\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7250 - val_loss: 0.5926 - val_accuracy: 0.6927\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.7222 - val_loss: 0.5917 - val_accuracy: 0.6927\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5557 - accuracy: 0.7211 - val_loss: 0.5908 - val_accuracy: 0.6927\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.7365 - val_loss: 0.5899 - val_accuracy: 0.6927\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5621 - accuracy: 0.7257 - val_loss: 0.5891 - val_accuracy: 0.6875\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5645 - accuracy: 0.7187 - val_loss: 0.5882 - val_accuracy: 0.6875\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7381 - val_loss: 0.5874 - val_accuracy: 0.6875\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.7096 - val_loss: 0.5866 - val_accuracy: 0.6875\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7439 - val_loss: 0.5858 - val_accuracy: 0.6875\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7410 - val_loss: 0.5849 - val_accuracy: 0.6875\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5526 - accuracy: 0.7224 - val_loss: 0.5841 - val_accuracy: 0.6875\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5451 - accuracy: 0.7062 - val_loss: 0.5834 - val_accuracy: 0.6875\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7624 - val_loss: 0.5826 - val_accuracy: 0.6875\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.7210 - val_loss: 0.5818 - val_accuracy: 0.6875\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7581 - val_loss: 0.5810 - val_accuracy: 0.6875\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.7001 - val_loss: 0.5802 - val_accuracy: 0.6927\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7516 - val_loss: 0.5795 - val_accuracy: 0.6927\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7354 - val_loss: 0.5787 - val_accuracy: 0.6927\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7504 - val_loss: 0.5779 - val_accuracy: 0.6927\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7287 - val_loss: 0.5772 - val_accuracy: 0.6927\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7428 - val_loss: 0.5764 - val_accuracy: 0.6927\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7263 - val_loss: 0.5757 - val_accuracy: 0.6927\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.6998 - val_loss: 0.5750 - val_accuracy: 0.6927\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5320 - accuracy: 0.7302 - val_loss: 0.5742 - val_accuracy: 0.6927\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7229 - val_loss: 0.5735 - val_accuracy: 0.6927\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.7494 - val_loss: 0.5728 - val_accuracy: 0.6927\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.7323 - val_loss: 0.5721 - val_accuracy: 0.6927\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7377 - val_loss: 0.5714 - val_accuracy: 0.6979\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7563 - val_loss: 0.5707 - val_accuracy: 0.6979\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7041 - val_loss: 0.5700 - val_accuracy: 0.6979\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7172 - val_loss: 0.5693 - val_accuracy: 0.7031\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7468 - val_loss: 0.5686 - val_accuracy: 0.7031\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.6953 - val_loss: 0.5680 - val_accuracy: 0.7031\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.7104 - val_loss: 0.5674 - val_accuracy: 0.7031\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7533 - val_loss: 0.5668 - val_accuracy: 0.7031\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7364 - val_loss: 0.5661 - val_accuracy: 0.7031\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7712 - val_loss: 0.5655 - val_accuracy: 0.7031\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7318 - val_loss: 0.5649 - val_accuracy: 0.7031\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7243 - val_loss: 0.5643 - val_accuracy: 0.7083\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7135 - val_loss: 0.5637 - val_accuracy: 0.7083\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7053 - val_loss: 0.5631 - val_accuracy: 0.7083\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7138 - val_loss: 0.5625 - val_accuracy: 0.7083\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7356 - val_loss: 0.5619 - val_accuracy: 0.7083\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7344 - val_loss: 0.5613 - val_accuracy: 0.7083\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7620 - val_loss: 0.5607 - val_accuracy: 0.7135\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5183 - accuracy: 0.7180 - val_loss: 0.5602 - val_accuracy: 0.7135\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7375 - val_loss: 0.5596 - val_accuracy: 0.7083\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7278 - val_loss: 0.5591 - val_accuracy: 0.7083\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7450 - val_loss: 0.5585 - val_accuracy: 0.7083\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7194 - val_loss: 0.5580 - val_accuracy: 0.7083\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.7142 - val_loss: 0.5575 - val_accuracy: 0.7083\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7422 - val_loss: 0.5570 - val_accuracy: 0.7083\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7431 - val_loss: 0.5565 - val_accuracy: 0.7083\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.7234 - val_loss: 0.5561 - val_accuracy: 0.7083\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5149 - accuracy: 0.7348 - val_loss: 0.5556 - val_accuracy: 0.7083\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7591 - val_loss: 0.5552 - val_accuracy: 0.7083\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7375 - val_loss: 0.5547 - val_accuracy: 0.7083\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7307 - val_loss: 0.5543 - val_accuracy: 0.7135\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7542 - val_loss: 0.5538 - val_accuracy: 0.7135\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4806 - accuracy: 0.7721 - val_loss: 0.5534 - val_accuracy: 0.7135\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4795 - accuracy: 0.7589 - val_loss: 0.5530 - val_accuracy: 0.7188\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7517 - val_loss: 0.5526 - val_accuracy: 0.7135\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4962 - accuracy: 0.7641 - val_loss: 0.5522 - val_accuracy: 0.7188\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4830 - accuracy: 0.7523 - val_loss: 0.5518 - val_accuracy: 0.7188\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7317 - val_loss: 0.5514 - val_accuracy: 0.7188\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7721 - val_loss: 0.5510 - val_accuracy: 0.7188\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7397 - val_loss: 0.5506 - val_accuracy: 0.7188\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7648 - val_loss: 0.5502 - val_accuracy: 0.7188\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7379 - val_loss: 0.5498 - val_accuracy: 0.7188\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7436 - val_loss: 0.5494 - val_accuracy: 0.7188\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7550 - val_loss: 0.5491 - val_accuracy: 0.7188\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7231 - val_loss: 0.5487 - val_accuracy: 0.7188\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.7603 - val_loss: 0.5483 - val_accuracy: 0.7188\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4977 - accuracy: 0.7426 - val_loss: 0.5480 - val_accuracy: 0.7188\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.7426 - val_loss: 0.5476 - val_accuracy: 0.7188\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7278 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7644 - val_loss: 0.5470 - val_accuracy: 0.7240\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7553 - val_loss: 0.5466 - val_accuracy: 0.7240\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7453 - val_loss: 0.5463 - val_accuracy: 0.7240\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7373 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7765 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7330 - val_loss: 0.5453 - val_accuracy: 0.7240\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7366 - val_loss: 0.5450 - val_accuracy: 0.7240\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7585 - val_loss: 0.5447 - val_accuracy: 0.7240\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7563 - val_loss: 0.5444 - val_accuracy: 0.7240\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7892 - val_loss: 0.5441 - val_accuracy: 0.7240\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7871 - val_loss: 0.5438 - val_accuracy: 0.7240\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7702 - val_loss: 0.5435 - val_accuracy: 0.7240\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7602 - val_loss: 0.5431 - val_accuracy: 0.7240\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7863 - val_loss: 0.5428 - val_accuracy: 0.7240\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5016 - accuracy: 0.7482 - val_loss: 0.5425 - val_accuracy: 0.7240\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7764 - val_loss: 0.5422 - val_accuracy: 0.7240\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7733 - val_loss: 0.5419 - val_accuracy: 0.7240\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7667 - val_loss: 0.5416 - val_accuracy: 0.7188\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5033 - accuracy: 0.7518 - val_loss: 0.5413 - val_accuracy: 0.7188\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.7676 - val_loss: 0.5410 - val_accuracy: 0.7188\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7731 - val_loss: 0.5407 - val_accuracy: 0.7188\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7683 - val_loss: 0.5404 - val_accuracy: 0.7188\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7800 - val_loss: 0.5401 - val_accuracy: 0.7240\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.7724 - val_loss: 0.5399 - val_accuracy: 0.7240\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7742 - val_loss: 0.5396 - val_accuracy: 0.7292\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7783 - val_loss: 0.5393 - val_accuracy: 0.7292\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7626 - val_loss: 0.5390 - val_accuracy: 0.7292\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7640 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7453 - val_loss: 0.5384 - val_accuracy: 0.7292\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7432 - val_loss: 0.5382 - val_accuracy: 0.7292\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7670 - val_loss: 0.5379 - val_accuracy: 0.7292\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7723 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7995 - val_loss: 0.5374 - val_accuracy: 0.7344\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.7708 - val_loss: 0.5371 - val_accuracy: 0.7344\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.7729 - val_loss: 0.5369 - val_accuracy: 0.7344\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7897 - val_loss: 0.5366 - val_accuracy: 0.7396\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7983 - val_loss: 0.5364 - val_accuracy: 0.7396\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7787 - val_loss: 0.5362 - val_accuracy: 0.7396\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7838 - val_loss: 0.5359 - val_accuracy: 0.7396\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.7545 - val_loss: 0.5357 - val_accuracy: 0.7396\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7608 - val_loss: 0.5355 - val_accuracy: 0.7396\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7811 - val_loss: 0.5353 - val_accuracy: 0.7396\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7826 - val_loss: 0.5351 - val_accuracy: 0.7396\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7968 - val_loss: 0.5349 - val_accuracy: 0.7396\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7833 - val_loss: 0.5347 - val_accuracy: 0.7396\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7780 - val_loss: 0.5345 - val_accuracy: 0.7448\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7848 - val_loss: 0.5343 - val_accuracy: 0.7448\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.8021 - val_loss: 0.5341 - val_accuracy: 0.7448\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.7817 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7981 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7833 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7656 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.8047 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7793 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.8119 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7757 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7943 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7769 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.8116 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.8030 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7859 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7714 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7984 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7890 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7838 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7633 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7947 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7982 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7806 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7892 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7585 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7948 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7696 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.7777 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.8017 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7945 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7975 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7595 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7935 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.8027 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7844 - val_loss: 0.5297 - val_accuracy: 0.7552\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.8049 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7855 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.7983 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7653 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7716 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7858 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.8070 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8309 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7933 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7870 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7920 - val_loss: 0.5286 - val_accuracy: 0.7552\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7922 - val_loss: 0.5285 - val_accuracy: 0.7552\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7934 - val_loss: 0.5284 - val_accuracy: 0.7552\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7790 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7764 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4572 - accuracy: 0.7922 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.7901 - val_loss: 0.5280 - val_accuracy: 0.7552\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.8046 - val_loss: 0.5279 - val_accuracy: 0.7552\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7986 - val_loss: 0.5278 - val_accuracy: 0.7552\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7799 - val_loss: 0.5278 - val_accuracy: 0.7552\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7883 - val_loss: 0.5277 - val_accuracy: 0.7552\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7890 - val_loss: 0.5276 - val_accuracy: 0.7552\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7955 - val_loss: 0.5275 - val_accuracy: 0.7552\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7547 - val_loss: 0.5275 - val_accuracy: 0.7552\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.7980 - val_loss: 0.5274 - val_accuracy: 0.7552\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7831 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8124 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7826 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7841 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7564 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7904 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7754 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7970 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7926 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7979 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.7644 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7867 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7670 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.8070 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.8022 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7898 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.8152 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7754 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7838 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7868 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.8001 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7703 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7734 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7797 - val_loss: 0.5266 - val_accuracy: 0.7448\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.8082 - val_loss: 0.5266 - val_accuracy: 0.7448\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7975 - val_loss: 0.5266 - val_accuracy: 0.7448\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7785 - val_loss: 0.5266 - val_accuracy: 0.7448\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7936 - val_loss: 0.5266 - val_accuracy: 0.7448\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8009 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.7815 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.7931 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7816 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7640 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8074 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7994 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7730 - val_loss: 0.5264 - val_accuracy: 0.7448\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7780 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.7958 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7753 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4906 - accuracy: 0.7563 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7912 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7948 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.8006 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.8033 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7876 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4738 - accuracy: 0.7853 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7908 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7856 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7733 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7610 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7708 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7916 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.8064 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7610 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4995 - accuracy: 0.7640 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.8062 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4938 - accuracy: 0.7707 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7886 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.8046 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7961 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7968 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7995 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7768 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7753 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.7729 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8033 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7998 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.8014 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7853 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7914 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7785 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7808 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8077 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7816 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.8112 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.7808 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.7922 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7744 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7909 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7810 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.8068 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8143 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.7764 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7892 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7991 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7994 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7892 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7833 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7922 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7697 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7810 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.7759 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4472 - accuracy: 0.7926 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7724 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.7947 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7735 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8022 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7953 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7981 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7916 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.7617 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7772 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7851 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.7790 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.7752 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7920 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7850 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7767 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7873 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7968 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7907 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7976 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7905 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4502 - accuracy: 0.7754 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8221 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.7842 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8128 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.8014 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7902 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7808 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7925 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7854 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8003 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.7723 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7976 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7901 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7915 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7832 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7814 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7672 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7764 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.7865 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7735 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7921 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.8034 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7791 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8078 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.8109 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7780 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7733 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.7902 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7908 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7789 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7871 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7838 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4751 - accuracy: 0.7669 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7966 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7717 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7897 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.8197 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.8043 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.8021 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7731 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.7972 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.7844 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7896 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7983 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7767 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7561 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8010 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.7944 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8081 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.7862 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4924 - accuracy: 0.7611 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4746 - accuracy: 0.7711 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7957 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7918 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7707 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8005 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8126 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7978 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7896 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7803 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7847 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7744 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.8013 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7684 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.8017 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.8145 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8080 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7999 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.7796 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7704 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7941 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7792 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7917 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7705 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7686 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.8009 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.8002 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.8024 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7642 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8033 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7939 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7745 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.8007 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7675 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7942 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7482 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7890 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7994 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.8046 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.7928 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7796 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7580 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7883 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7919 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.7794 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7687 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7611 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7897 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7946 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7552 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.7926 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7768 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.8069 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8079 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7892 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.7989 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7783 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7785 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7698 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7991 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7904 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7833 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.7958 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8063 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7872 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.8058 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8118 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7717 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7728 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7900 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.7872 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8007 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7991 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7879 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8000 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7906 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4917 - accuracy: 0.7419 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.7784 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7913 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7984 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7759 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.7602 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7836 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7842 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7657 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7833 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7786 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.7961 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7794 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7896 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7801 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.7751 - val_loss: 0.5251 - val_accuracy: 0.7448\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7942 - val_loss: 0.5251 - val_accuracy: 0.7448\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.7981 - val_loss: 0.5251 - val_accuracy: 0.7448\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7869 - val_loss: 0.5251 - val_accuracy: 0.7448\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7836 - val_loss: 0.5251 - val_accuracy: 0.7448\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8035 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7763 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.7755 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8007 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.7603 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7778 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7813 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7669 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7945 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7823 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7811 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4754 - accuracy: 0.7668 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7821 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7849 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8002 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7756 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.8018 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8042 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7703 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7802 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4541 - accuracy: 0.7610 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7897 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8140 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.7536 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8266 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7908 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7861 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.7981 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.7666 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7839 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7625 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7762 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7676 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7763 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7634 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7802 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7656 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7873 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.7562 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7692 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7739 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7765 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7790 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7867 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7901 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.7752 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7906 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7628 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7707 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.7751 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7742 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.7775 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7642 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7691 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4800 - accuracy: 0.7590 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7902 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.7668 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.7986 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7846 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.7702 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7656 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.7891 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7761 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.7507 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.7959 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.7879 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7501 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7680 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7832 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8189 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.7660 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7735 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4802 - accuracy: 0.7345 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7832 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7677 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7750 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7795 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7953 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8007 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7728 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7886 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.7967 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7909 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7913 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7726 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7677 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7884 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.7864 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8164 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7997 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7927 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7549 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.7901 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7805 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7753 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.7908 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8249 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7888 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7609 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7850 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7812 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.8047 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8059 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.7687 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7745 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7945 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7671 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7993 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7787 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7946 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.7473 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7841 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7824 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7968 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7791 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7666 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.7902 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7903 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8129 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7914 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.7981 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4389 - accuracy: 0.7824 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.8020 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7860 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7888 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.7789 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7960 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.7685 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.7903 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.7629 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.7873 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8042 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7738 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.7501 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7794 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7762 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7900 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.7652 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7825 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7768 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7905 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.7723 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7779 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7748 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.7871 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7814 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7764 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7803 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.7848 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7994 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.7823 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7960 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7934 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7874 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7593 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.7775 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7751 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.7884 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.7679 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7550 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8059 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7838 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7876 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7785 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7830 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7970 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7544 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.7924 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.7774 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7825 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7648 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7748 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.7746 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7849 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.7928 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.7941 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.7870 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7379 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7825 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.7978 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7696 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7803 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7638 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7940 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8047 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8019 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.7991 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7855 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.7800 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.7802 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7943 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7835 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.7872 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7696 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.8013 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.7798 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7928 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7962 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7841 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.7890 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.7565 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7849 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7872 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7847 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4301 - accuracy: 0.7989 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7831 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8003 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.7932 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7755 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7862 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7823 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.7683 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.7573 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.7868 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8112 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.7592 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.7607 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7582 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.7781 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7875 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.7790 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.7824 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7809 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.7821 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7620 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7627 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7641 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7692 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7927 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7855 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7621 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7961 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.7676 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.7480 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7779 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4356 - accuracy: 0.7773 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7694 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7895 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.7897 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8038 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7894 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7957 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.7955 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7945 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.7937 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7860 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7654 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.7463 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.7813 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.7875 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.7896 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7903 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8078 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.7994 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7711 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7702 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8020 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.7649 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7786 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7703 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7938 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7867 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.7759 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.7813 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.7967 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7764 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.7826 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8044 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7836 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7850 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7831 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.7948 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7716 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7751 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7783 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8172 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.7869 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7649 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7739 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.8037 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7546 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8006 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.7974 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7719 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7673 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.7832 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7840 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7984 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7731 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7846 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7821 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.7973 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7767 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7789 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7776 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7910 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7745 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7814 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.7763 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7843 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7791 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7623 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8077 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.7840 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7754 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.7793 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.7848 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.7960 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.7972 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.7905 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.7982 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8101 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.7787 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.7765 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7559 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7540 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7779 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7422 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7513 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7658 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7777 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7695 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.7560 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7729 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.7957 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7818 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7908 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7983 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.7956 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7815 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8024 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7862 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.7929 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7857 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7880 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7718 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8034 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7704 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8063 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4813 - accuracy: 0.7348 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.7688 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7728 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.7857 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7668 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7722 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7911 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7794 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7521 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7903 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7801 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.7824 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7914 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.7885 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7859 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7692 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7613 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7984 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4083 - accuracy: 0.7940 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.7640 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7826 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7726 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.7758 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.7988 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7707 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7840 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.7851 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7824 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.7891 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7806 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8027 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.7952 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7822 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.7800 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.7931 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7880 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.7962 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7896 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7761 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7785 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7775 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3848 - accuracy: 0.8198 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7825 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7603 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8024 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.7737 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7354 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7866 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7837 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8077 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.7660 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7980 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7795 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7851 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7592 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.7965 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7726 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.7727 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7731 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7698 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7858 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7737 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.7960 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7771 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.7896 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.7756 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.7846 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.7860 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7879 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8065 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.7924 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8014 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4374 - accuracy: 0.7753 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4620 - accuracy: 0.7611 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7604 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.7985 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8063 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7607 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7733 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.7951 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.7780 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.7708 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.7849 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7492 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7641 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7833 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7653 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8127 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7909 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.7633 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.7943 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.7969 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7841 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.7777 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7523 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.7698 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7809 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.7850 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.7945 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.7634 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.8001 - val_loss: 0.5272 - val_accuracy: 0.7448\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7949 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.7974 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8104 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8226 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7923 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7745 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4304 - accuracy: 0.7848 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4805 - accuracy: 0.7580 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8076 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.8062 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.7993 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8118 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7637 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8104 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7730 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7888 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.7926 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7629 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.7540 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7837 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7729 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.7704 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7896 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7906 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.7895 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7712 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7814 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7845 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8139 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4258 - accuracy: 0.7851 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.7995 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.7781 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7660 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7836 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7882 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8013 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7930 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.7781 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.7922 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7440 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.7766 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7826 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7575 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.7949 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.7717 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.7973 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7788 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.7878 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7860 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7824 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7840 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8096 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7869 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7849 - val_loss: 0.5278 - val_accuracy: 0.7500\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7811 - val_loss: 0.5278 - val_accuracy: 0.7500\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4196 - accuracy: 0.7818 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.7889 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.7713 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7820 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7786 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.7843 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7998 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7829 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7983 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7717 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7942 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7869 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.7823 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.7716 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.7717 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.7788 - val_loss: 0.5281 - val_accuracy: 0.7500\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7793 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.7968 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.7660 - val_loss: 0.5281 - val_accuracy: 0.7500\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4042 - accuracy: 0.8156 - val_loss: 0.5281 - val_accuracy: 0.7500\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8056 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.7522 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.7594 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7745 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.7936 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.7920 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8059 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.7844 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7640 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.7744 - val_loss: 0.5282 - val_accuracy: 0.7500\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.8022 - val_loss: 0.5282 - val_accuracy: 0.7500\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8195 - val_loss: 0.5282 - val_accuracy: 0.7500\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.7918 - val_loss: 0.5282 - val_accuracy: 0.7500\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7808 - val_loss: 0.5282 - val_accuracy: 0.7500\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4253 - accuracy: 0.7885 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7666 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.7917 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8036 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.7938 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7777 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.7906 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.7260 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4372 - accuracy: 0.7809 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.7730 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.7989 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7909 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.7805 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.7825 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.7962 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.7861 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.7732 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.8202 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7718 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.7869 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4407 - accuracy: 0.7803 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.7725 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4587 - accuracy: 0.7716 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.7849 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.7913 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7746 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3900 - accuracy: 0.8162 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7699 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.7797 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7917 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.7830 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8027 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.7703 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4428 - accuracy: 0.7671 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.7702 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8054 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7929 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.7896 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4369 - accuracy: 0.7778 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.7640 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7952 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7876 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.8048 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.7860 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7473 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4350 - accuracy: 0.7804 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7699 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7829 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.7805 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7603 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.7920 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4263 - accuracy: 0.7665 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7943 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7698 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7660 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8093 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7880 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.7771 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7865 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8003 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7599 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.7997 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8079 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7924 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7923 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.7887 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7967 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.7772 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7635 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7854 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7858 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.7763 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.7766 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7889 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.7564 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4252 - accuracy: 0.7810 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4288 - accuracy: 0.7841 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.7820 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.7961 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.7688 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.7813 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.7703 - val_loss: 0.5290 - val_accuracy: 0.7396\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.7903 - val_loss: 0.5291 - val_accuracy: 0.7396\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7899 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7793 - val_loss: 0.5291 - val_accuracy: 0.7396\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.7846 - val_loss: 0.5291 - val_accuracy: 0.7396\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7729 - val_loss: 0.5291 - val_accuracy: 0.7396\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7888 - val_loss: 0.5291 - val_accuracy: 0.7396\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.7795 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4084 - accuracy: 0.7927 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.7977 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.7925 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7644 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8003 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8017 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7856 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8064 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3938 - accuracy: 0.8076 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7893 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7818 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7780 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.7951 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7717 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.7751 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7885 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.7740 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.7606 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.8044 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7727 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.7842 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.7969 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8049 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7898 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7647 - val_loss: 0.5295 - val_accuracy: 0.7396\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7671 - val_loss: 0.5295 - val_accuracy: 0.7396\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7895 - val_loss: 0.5295 - val_accuracy: 0.7396\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.7963 - val_loss: 0.5295 - val_accuracy: 0.7396\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8012 - val_loss: 0.5295 - val_accuracy: 0.7396\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7722 - val_loss: 0.5295 - val_accuracy: 0.7396\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7823 - val_loss: 0.5295 - val_accuracy: 0.7396\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.7857 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.7809 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.7689 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.7811 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4354 - accuracy: 0.7601 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7519 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8134 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8006 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7682 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7800 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7702 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.7889 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.8018 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4495 - accuracy: 0.7741 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.7577 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.8013 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7920 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7791 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7702 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7779 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.7894 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.7947 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7814 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3839 - accuracy: 0.8173 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.7840 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7665 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.7838 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.7777 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.7733 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.7976 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.7722 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.7818 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.7802 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7754 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8155 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7435 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8045 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.7931 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.7965 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.7864 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4646 - accuracy: 0.7476 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8056 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.7869 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7858 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8057 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7844 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7987 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.7723 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.7993 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7924 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.7509 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7857 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.7998 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.7967 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7891 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7777 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.7923 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.7938 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.7694 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7793 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.7952 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7839 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7676 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7787 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7657 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7921 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.7653 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8100 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.7766 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.7940 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4365 - accuracy: 0.7834 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.7796 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7807 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4135 - accuracy: 0.7934 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7733 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.7974 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7734 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7785 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7831 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.7842 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7646 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7687 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.7898 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8061 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8012 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7887 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.7895 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.7764 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4086 - accuracy: 0.7864 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7779 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7823 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.7871 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.7992 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7832 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.7838 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4472 - accuracy: 0.7674 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.7617 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.7788 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.7938 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.7638 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.7894 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.7736 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.7910 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4388 - accuracy: 0.7702 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7527 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7880 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4350 - accuracy: 0.7839 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.7839 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.7763 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7866 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.7720 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.7920 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7652 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8103 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7803 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7631 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7597 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.7782 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7949 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7688 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7542 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.7915 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8185 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7782 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.7906 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.7925 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.7745 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8042 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7791 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.7885 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7766 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7748 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.7864 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.7822 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.7872 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.7939 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.7823 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7619 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4540 - accuracy: 0.7641 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4262 - accuracy: 0.7981 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8051 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7841 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7532 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7832 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7736 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7579 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.7898 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.7856 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.7879 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7940 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.7901 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.7799 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.7876 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8052 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.7529 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.7699 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4336 - accuracy: 0.7733 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7565 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8076 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7670 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.7794 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8116 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8162 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7747 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.7616 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7869 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.7857 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.7727 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7753 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.7875 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8133 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8043 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7578 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.7886 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.7911 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7935 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7699 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.7868 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7991 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.7913 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7911 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.7974 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.8024 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4174 - accuracy: 0.7841 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7613 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7727 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.7914 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4354 - accuracy: 0.7656 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8101 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.8000 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.7797 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7956 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8065 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8051 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.7953 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7595 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7821 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7603 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.7813 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7828 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.7794 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7679 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.7952 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4423 - accuracy: 0.7599 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7543 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.7601 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.7743 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.7723 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.7908 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.7970 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7869 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4070 - accuracy: 0.7838 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.7672 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7640 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7903 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.7598 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7952 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7741 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.7985 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.7792 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7771 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.7929 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.7606 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.7812 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.7883 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7699 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.7706 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8239 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.7887 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.7745 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7726 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7623 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.7892 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.7765 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7978 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7521 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8100 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7752 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7678 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.7774 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7765 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.7909 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7994 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7558 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.7452 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.7943 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7924 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.7846 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.7963 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7602 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.7848 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.7890 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8014 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7814 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7869 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7628 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7891 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7901 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7923 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7956 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.7714 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7654 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.7948 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7832 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7650 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7753 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8002 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.7792 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.7823 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7708 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4055 - accuracy: 0.8037 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.7756 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.7897 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.7908 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.7774 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7887 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7760 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.7751 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7884 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.7869 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4080 - accuracy: 0.7959 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7958 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7835 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.7957 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.7570 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.7757 - val_loss: 0.5303 - val_accuracy: 0.7396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZVxOXbvSS98",
        "outputId": "44953345-dcc7-43d3-fa70-869455e4b4b7"
      },
      "source": [
        "run_hist_2.history.keys()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "0jG0yIkwSS99",
        "outputId": "f3326019-a701-4f0d-862c-745ae35cc753"
      },
      "source": [
        "n = len(run_hist_2.history[\"loss\"])\n",
        "\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
        "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
        "ax.legend()\n",
        "ax.set_title('Loss over iterations')\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
        "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
        "ax.legend(loc='lower right')\n",
        "ax.set_title('Accuracy over iterations')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Accuracy over iterations')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "h5KTUJF1SS99",
        "outputId": "4d2a9e00-db04-48ce-9401-a1ccbc8c6b3c"
      },
      "source": [
        "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
        "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
        "print('')\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
        "### END SOLUTION"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "accuracy is 0.740\n",
            "roc-auc is 0.793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGjCYcyiSS99"
      },
      "source": [
        "---\n",
        "### Machine Learning Foundation (C) 2020 IBM Corporation"
      ]
    }
  ]
}